{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINED_DATA = os.path.join('..', 'data', 'combined-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>TrackId</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Album</th>\n",
       "      <th>Image</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958</td>\n",
       "      <td>Domenico Modugno</td>\n",
       "      <td>Nel Blu Dipinto Di Blu (Volare)</td>\n",
       "      <td>https://open.spotify.com/track/006Ndmw2hHxvnLb...</td>\n",
       "      <td>006Ndmw2hHxvnLbJsBFnPx</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>Tutto Modugno (Mister Volare)</td>\n",
       "      <td>https://i.scdn.co/image/5e8c49f7a8d161c1d65109...</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1958</td>\n",
       "      <td>Henry Mancini</td>\n",
       "      <td>The Music From Peter Gunn</td>\n",
       "      <td>https://open.spotify.com/track/3BdPP6Xce6FUcfa...</td>\n",
       "      <td>3BdPP6Xce6FUcfaCFsnZIg</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.550</td>\n",
       "      <td>177733.0</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>138.037</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>The music from Peter Gunn</td>\n",
       "      <td>https://i.scdn.co/image/1ad2e8ce1f988c27678298...</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1958</td>\n",
       "      <td>Domenico Modugno, songwriter (Domenico Modugno)</td>\n",
       "      <td>Nel Blu Dipinto Di Blu (Volare)</td>\n",
       "      <td>https://open.spotify.com/track/006Ndmw2hHxvnLb...</td>\n",
       "      <td>006Ndmw2hHxvnLbJsBFnPx</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>Tutto Modugno (Mister Volare)</td>\n",
       "      <td>https://i.scdn.co/image/5e8c49f7a8d161c1d65109...</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>Ella Fitzgerald</td>\n",
       "      <td>Ella Fitzgerald Sings The Irving Berlin Song Book</td>\n",
       "      <td>https://open.spotify.com/track/5FY0EikZVSBOwpj...</td>\n",
       "      <td>5FY0EikZVSBOwpjQa9S5Ii</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.615</td>\n",
       "      <td>138320.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>73.007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>Ella Fitzgerald Sings The Irving Berlin Song Book</td>\n",
       "      <td>https://i.scdn.co/image/3350581fb4712a44a6f6b5...</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>Perry Como</td>\n",
       "      <td>Catch A Falling Star</td>\n",
       "      <td>https://open.spotify.com/track/38YMdelhj62vJ6d...</td>\n",
       "      <td>38YMdelhj62vJ6d5a0wxMQ</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.628</td>\n",
       "      <td>148493.0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>118.895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>It's Impossible</td>\n",
       "      <td>https://i.scdn.co/image/0a33dd0dbd1b416c245c8c...</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                           Artist  \\\n",
       "0  1958                                 Domenico Modugno   \n",
       "1  1958                                    Henry Mancini   \n",
       "2  1958  Domenico Modugno, songwriter (Domenico Modugno)   \n",
       "3  1958                                  Ella Fitzgerald   \n",
       "4  1958                                       Perry Como   \n",
       "\n",
       "                                               Title  \\\n",
       "0                    Nel Blu Dipinto Di Blu (Volare)   \n",
       "1                          The Music From Peter Gunn   \n",
       "2                    Nel Blu Dipinto Di Blu (Volare)   \n",
       "3  Ella Fitzgerald Sings The Irving Berlin Song Book   \n",
       "4                               Catch A Falling Star   \n",
       "\n",
       "                                                 URL                 TrackId  \\\n",
       "0  https://open.spotify.com/track/006Ndmw2hHxvnLb...  006Ndmw2hHxvnLbJsBFnPx   \n",
       "1  https://open.spotify.com/track/3BdPP6Xce6FUcfa...  3BdPP6Xce6FUcfaCFsnZIg   \n",
       "2  https://open.spotify.com/track/006Ndmw2hHxvnLb...  006Ndmw2hHxvnLbJsBFnPx   \n",
       "3  https://open.spotify.com/track/5FY0EikZVSBOwpj...  5FY0EikZVSBOwpjQa9S5Ii   \n",
       "4  https://open.spotify.com/track/38YMdelhj62vJ6d...  38YMdelhj62vJ6d5a0wxMQ   \n",
       "\n",
       "   Acousticness  Danceability  Duration (ms)  Energy  Instrumentalness  ...    \\\n",
       "0         0.987         0.518       216373.0   0.060          0.000008  ...     \n",
       "1         0.893         0.550       177733.0   0.318          0.881000  ...     \n",
       "2         0.987         0.518       216373.0   0.060          0.000008  ...     \n",
       "3         0.675         0.615       138320.0   0.186          0.000000  ...     \n",
       "4         0.864         0.628       148493.0   0.172          0.000000  ...     \n",
       "\n",
       "   Mode  Speechiness    Tempo  Time Signature  Valence  \\\n",
       "0   1.0       0.0441  127.870             4.0    0.336   \n",
       "1   1.0       0.0313  138.037             4.0    0.620   \n",
       "2   1.0       0.0441  127.870             4.0    0.336   \n",
       "3   0.0       0.0508   73.007             4.0    0.749   \n",
       "4   1.0       0.0600  118.895             3.0    0.475   \n",
       "\n",
       "                                               Album  \\\n",
       "0                      Tutto Modugno (Mister Volare)   \n",
       "1                          The music from Peter Gunn   \n",
       "2                      Tutto Modugno (Mister Volare)   \n",
       "3  Ella Fitzgerald Sings The Irving Berlin Song Book   \n",
       "4                                    It's Impossible   \n",
       "\n",
       "                                               Image  Explicit Popularity  \\\n",
       "0  https://i.scdn.co/image/5e8c49f7a8d161c1d65109...     False       35.0   \n",
       "1  https://i.scdn.co/image/1ad2e8ce1f988c27678298...     False       16.0   \n",
       "2  https://i.scdn.co/image/5e8c49f7a8d161c1d65109...     False       35.0   \n",
       "3  https://i.scdn.co/image/3350581fb4712a44a6f6b5...     False       34.0   \n",
       "4  https://i.scdn.co/image/0a33dd0dbd1b416c245c8c...     False       44.0   \n",
       "\n",
       "  Winner  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df = pd.read_csv(COMBINED_DATA)\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Artist', 'Title', 'URL', 'TrackId', 'Acousticness',\n",
       "       'Danceability', 'Duration (ms)', 'Energy', 'Instrumentalness', 'Key',\n",
       "       'Liveness', 'Loudness', 'Mode', 'Speechiness', 'Tempo',\n",
       "       'Time Signature', 'Valence', 'Album', 'Image', 'Explicit', 'Popularity',\n",
       "       'Winner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>-14.887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.550</td>\n",
       "      <td>177733.0</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>-14.516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>138.037</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>-14.887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.615</td>\n",
       "      <td>138320.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>-12.382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>73.007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.628</td>\n",
       "      <td>148493.0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>-17.816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>118.895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Acousticness  Danceability  Duration (ms)  Energy  Instrumentalness  \\\n",
       "0  1958         0.987         0.518       216373.0   0.060          0.000008   \n",
       "1  1958         0.893         0.550       177733.0   0.318          0.881000   \n",
       "2  1958         0.987         0.518       216373.0   0.060          0.000008   \n",
       "3  1958         0.675         0.615       138320.0   0.186          0.000000   \n",
       "4  1958         0.864         0.628       148493.0   0.172          0.000000   \n",
       "\n",
       "    Key  Liveness  Loudness  Mode  Speechiness    Tempo  Time Signature  \\\n",
       "0  10.0    0.1610   -14.887   1.0       0.0441  127.870             4.0   \n",
       "1   0.0    0.0311   -14.516   1.0       0.0313  138.037             4.0   \n",
       "2  10.0    0.1610   -14.887   1.0       0.0441  127.870             4.0   \n",
       "3   0.0    0.1940   -12.382   0.0       0.0508   73.007             4.0   \n",
       "4  11.0    0.1130   -17.816   1.0       0.0600  118.895             3.0   \n",
       "\n",
       "   Valence  Explicit  Popularity  \n",
       "0    0.336     False        35.0  \n",
       "1    0.620     False        16.0  \n",
       "2    0.336     False        35.0  \n",
       "3    0.749     False        34.0  \n",
       "4    0.475     False        44.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = songs_df.drop(labels=['Artist', 'Title', 'URL', 'TrackId', 'Album', 'Image', 'Winner'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                  int64\n",
       "Acousticness        float64\n",
       "Danceability        float64\n",
       "Duration (ms)       float64\n",
       "Energy              float64\n",
       "Instrumentalness    float64\n",
       "Key                 float64\n",
       "Liveness            float64\n",
       "Loudness            float64\n",
       "Mode                float64\n",
       "Speechiness         float64\n",
       "Tempo               float64\n",
       "Time Signature      float64\n",
       "Valence             float64\n",
       "Explicit               bool\n",
       "Popularity          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Explicit = X.Explicit.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12983\n",
       "1     1061\n",
       "Name: Explicit, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.Explicit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluded_features = ['Popularity']\n",
    "excluded_features = ['Key']\n",
    "X.drop(labels=excluded_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = songs_df['Winner']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10754\n",
       "1     3290\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, shuffle=True, stratify=y)\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Convert labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14044, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dims = len(X.columns)\n",
    "# Create model and add layers\n",
    "def make_model(dense_layer_sizes, activation):\n",
    "    model = Sequential()\n",
    "    for dense_layer in dense_layer_sizes:\n",
    "        model.add(Dense(units=dense_layer, activation=activation, input_dim=dims))\n",
    "        \n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7022 samples, validate on 3511 samples\n",
      "Epoch 1/120\n",
      "7022/7022 [==============================] - 1s 92us/step - loss: 0.4673 - acc: 0.8033 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 2/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.4460 - acc: 0.8085 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 3/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.4347 - acc: 0.8132 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 4/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.4267 - acc: 0.8157 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 5/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.4204 - acc: 0.8173 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 6/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.4170 - acc: 0.8204 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 7/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.4132 - acc: 0.8250 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 8/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.4052 - acc: 0.8265 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 9/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.3999 - acc: 0.8277 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 10/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.3985 - acc: 0.8270 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 11/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.3920 - acc: 0.8304 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 12/120\n",
      "7022/7022 [==============================] - 0s 53us/step - loss: 0.3867 - acc: 0.8332 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 13/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.3831 - acc: 0.8382 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 14/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.3759 - acc: 0.8392 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 15/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.3745 - acc: 0.8389 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 16/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.3641 - acc: 0.8456 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 17/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3600 - acc: 0.8449 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 18/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.3588 - acc: 0.8448 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 19/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.3504 - acc: 0.8505 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 20/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3468 - acc: 0.8553 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 21/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.3416 - acc: 0.8526 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 22/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3344 - acc: 0.8603 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 23/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.3293 - acc: 0.8612 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 24/120\n",
      "7022/7022 [==============================] - 0s 39us/step - loss: 0.3259 - acc: 0.8627 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 25/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3188 - acc: 0.8674 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 26/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3141 - acc: 0.8671 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 27/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.3076 - acc: 0.8721 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 28/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3011 - acc: 0.8760 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 29/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.2978 - acc: 0.8744 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 30/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2905 - acc: 0.8821 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 31/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.2852 - acc: 0.8785 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 32/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2803 - acc: 0.8865 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 33/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.2748 - acc: 0.8851 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 34/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.2701 - acc: 0.8862 - val_loss: 12.2049 - val_acc: 0.2424\n",
      "Epoch 35/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.2644 - acc: 0.8905 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 36/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.2600 - acc: 0.8945 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 37/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.2536 - acc: 0.8972 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 38/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.2529 - acc: 0.8965 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 39/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.2457 - acc: 0.8993 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 40/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.2405 - acc: 0.9059 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 41/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.2347 - acc: 0.9059 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 42/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2318 - acc: 0.9081 - val_loss: 4.0987 - val_acc: 0.7457\n",
      "Epoch 43/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.2241 - acc: 0.9089 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 44/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2212 - acc: 0.9120 - val_loss: 4.0218 - val_acc: 0.7502\n",
      "Epoch 45/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2195 - acc: 0.9116 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 46/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2136 - acc: 0.9138 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 47/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2069 - acc: 0.9197 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 48/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2051 - acc: 0.9211 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 49/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.2006 - acc: 0.9228 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 50/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1941 - acc: 0.9269 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 51/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1920 - acc: 0.9271 - val_loss: 4.2317 - val_acc: 0.7371\n",
      "Epoch 52/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1861 - acc: 0.9308 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 53/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1798 - acc: 0.9288 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 54/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1778 - acc: 0.9346 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 55/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.1779 - acc: 0.9321 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 56/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1729 - acc: 0.9324 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 57/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.1766 - acc: 0.9322 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 58/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1628 - acc: 0.9415 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 59/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.1582 - acc: 0.9413 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 60/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1571 - acc: 0.9433 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 61/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.1512 - acc: 0.9437 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 62/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.1488 - acc: 0.9452 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 63/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1439 - acc: 0.9470 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 64/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1406 - acc: 0.9504 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 65/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1423 - acc: 0.9475 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 66/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.1430 - acc: 0.9477 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 67/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1294 - acc: 0.9560 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 68/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1321 - acc: 0.9533 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 69/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1286 - acc: 0.9553 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 70/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.1213 - acc: 0.9553 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 71/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1268 - acc: 0.9539 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 72/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1215 - acc: 0.9583 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 73/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1100 - acc: 0.9627 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 74/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.1115 - acc: 0.9633 - val_loss: 11.0848 - val_acc: 0.3122\n",
      "Epoch 75/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1118 - acc: 0.9606 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 76/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.1133 - acc: 0.9607 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 77/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.1073 - acc: 0.9611 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 78/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1043 - acc: 0.9672 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 79/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.1081 - acc: 0.9620 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 80/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.1088 - acc: 0.9610 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 81/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0924 - acc: 0.9702 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 82/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.0868 - acc: 0.9714 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 83/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0866 - acc: 0.9727 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 84/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.0895 - acc: 0.9708 - val_loss: 5.8014 - val_acc: 0.6400\n",
      "Epoch 85/120\n",
      "7022/7022 [==============================] - 0s 42us/step - loss: 0.0870 - acc: 0.9725 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 86/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.1044 - acc: 0.9631 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 87/120\n",
      "7022/7022 [==============================] - 0s 40us/step - loss: 0.0838 - acc: 0.9751 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 88/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.0845 - acc: 0.9725 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 89/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0758 - acc: 0.9772 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 90/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0756 - acc: 0.9789 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 91/120\n",
      "7022/7022 [==============================] - 0s 53us/step - loss: 0.0791 - acc: 0.9734 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 92/120\n",
      "7022/7022 [==============================] - 0s 52us/step - loss: 0.0824 - acc: 0.9745 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 93/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0731 - acc: 0.9784 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 94/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0722 - acc: 0.9771 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 95/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0647 - acc: 0.9825 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 96/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0672 - acc: 0.9799 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 97/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0664 - acc: 0.9788 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 98/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0700 - acc: 0.9776 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 99/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0639 - acc: 0.9795 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 100/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0706 - acc: 0.9769 - val_loss: 4.0301 - val_acc: 0.7496\n",
      "Epoch 101/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0788 - acc: 0.9737 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 102/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0684 - acc: 0.9784 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 103/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0585 - acc: 0.9821 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 104/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0533 - acc: 0.9865 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 105/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0492 - acc: 0.9878 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 106/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0541 - acc: 0.9846 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 107/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0550 - acc: 0.9839 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 108/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0688 - acc: 0.9751 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 109/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0571 - acc: 0.9821 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 110/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0657 - acc: 0.9788 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 111/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0485 - acc: 0.9880 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 112/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0486 - acc: 0.9872 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 113/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.0414 - acc: 0.9890 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 114/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0381 - acc: 0.9907 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 115/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0365 - acc: 0.9916 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 116/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0476 - acc: 0.9866 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 117/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0617 - acc: 0.9788 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 118/120\n",
      "7022/7022 [==============================] - 0s 41us/step - loss: 0.0471 - acc: 0.9865 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 119/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0594 - acc: 0.9785 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 120/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.0462 - acc: 0.9869 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "3511/3511 [==============================] - 0s 13us/step\n",
      "7022/7022 [==============================] - 0s 12us/step\n",
      "Train on 7022 samples, validate on 3511 samples\n",
      "Epoch 1/120\n",
      "7022/7022 [==============================] - 1s 87us/step - loss: 0.4683 - acc: 0.8002 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 2/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.4421 - acc: 0.8122 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 3/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.4331 - acc: 0.8143 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 4/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.4253 - acc: 0.8190 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 5/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.4195 - acc: 0.8191 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 6/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.4132 - acc: 0.8214 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 7/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.4081 - acc: 0.8227 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 8/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.4039 - acc: 0.8254 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 9/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3984 - acc: 0.8273 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 10/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3944 - acc: 0.8311 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 11/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.3911 - acc: 0.8341 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 12/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3837 - acc: 0.8337 - val_loss: 12.3583 - val_acc: 0.2333\n",
      "Epoch 13/120\n",
      "7022/7022 [==============================] - 0s 43us/step - loss: 0.3779 - acc: 0.8392 - val_loss: 5.9776 - val_acc: 0.6280\n",
      "Epoch 14/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.3746 - acc: 0.8409 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 15/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3707 - acc: 0.8392 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 16/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.3657 - acc: 0.8431 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 17/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.3574 - acc: 0.8475 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 18/120\n",
      "7022/7022 [==============================] - 0s 55us/step - loss: 0.3532 - acc: 0.8480 - val_loss: 11.5011 - val_acc: 0.2854\n",
      "Epoch 19/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3471 - acc: 0.8499 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 20/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3422 - acc: 0.8553 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 21/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.3387 - acc: 0.8560 - val_loss: 3.8149 - val_acc: 0.7633\n",
      "Epoch 22/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3322 - acc: 0.8559 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 23/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3234 - acc: 0.8624 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 24/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3208 - acc: 0.8676 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 25/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3164 - acc: 0.8657 - val_loss: 12.3583 - val_acc: 0.2333\n",
      "Epoch 26/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3074 - acc: 0.8683 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 27/120\n",
      "7022/7022 [==============================] - 0s 56us/step - loss: 0.3046 - acc: 0.8687 - val_loss: 12.3583 - val_acc: 0.2333\n",
      "Epoch 28/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.2966 - acc: 0.8765 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 29/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.2936 - acc: 0.8741 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 30/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.2864 - acc: 0.8804 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 31/120\n",
      "7022/7022 [==============================] - 0s 52us/step - loss: 0.2800 - acc: 0.8808 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 32/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.2766 - acc: 0.8875 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 33/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.2687 - acc: 0.8884 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 34/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.2635 - acc: 0.8901 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 35/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.2612 - acc: 0.8949 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 36/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.2551 - acc: 0.8972 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 37/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2496 - acc: 0.8936 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 38/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.2457 - acc: 0.9003 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 39/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.2390 - acc: 0.9050 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 40/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.2355 - acc: 0.9056 - val_loss: 4.2566 - val_acc: 0.7354\n",
      "Epoch 41/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2282 - acc: 0.9104 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 42/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2230 - acc: 0.9099 - val_loss: 12.3537 - val_acc: 0.2336\n",
      "Epoch 43/120\n",
      "7022/7022 [==============================] - 0s 62us/step - loss: 0.2172 - acc: 0.9133 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 44/120\n",
      "7022/7022 [==============================] - 0s 52us/step - loss: 0.2136 - acc: 0.9126 - val_loss: 12.3407 - val_acc: 0.2341\n",
      "Epoch 45/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2085 - acc: 0.9184 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 46/120\n",
      "7022/7022 [==============================] - 0s 57us/step - loss: 0.2055 - acc: 0.9167 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 47/120\n",
      "7022/7022 [==============================] - 1s 148us/step - loss: 0.1977 - acc: 0.9212 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 48/120\n",
      "7022/7022 [==============================] - 0s 67us/step - loss: 0.1955 - acc: 0.9222 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 49/120\n",
      "7022/7022 [==============================] - 0s 68us/step - loss: 0.1919 - acc: 0.9227 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 50/120\n",
      "7022/7022 [==============================] - 0s 69us/step - loss: 0.1889 - acc: 0.9248 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 51/120\n",
      "7022/7022 [==============================] - 0s 63us/step - loss: 0.1879 - acc: 0.9251 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 52/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1828 - acc: 0.9269 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 53/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.1750 - acc: 0.9322 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 54/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.1688 - acc: 0.9338 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 55/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.1664 - acc: 0.9341 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 56/120\n",
      "7022/7022 [==============================] - 0s 59us/step - loss: 0.1621 - acc: 0.9415 - val_loss: 12.3950 - val_acc: 0.2310\n",
      "Epoch 57/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1579 - acc: 0.9423 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 58/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1629 - acc: 0.9358 - val_loss: 6.9772 - val_acc: 0.5665\n",
      "Epoch 59/120\n",
      "7022/7022 [==============================] - 0s 53us/step - loss: 0.1524 - acc: 0.9400 - val_loss: 12.2940 - val_acc: 0.2373\n",
      "Epoch 60/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.1515 - acc: 0.9429 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 61/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1473 - acc: 0.9436 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 62/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1413 - acc: 0.9484 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 63/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1405 - acc: 0.9480 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 64/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1395 - acc: 0.9486 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 65/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1346 - acc: 0.9483 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 66/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.1284 - acc: 0.9526 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 67/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1291 - acc: 0.9510 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 68/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1298 - acc: 0.9536 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 69/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1183 - acc: 0.9584 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 70/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1148 - acc: 0.9583 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 71/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1149 - acc: 0.9596 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 72/120\n",
      "7022/7022 [==============================] - 0s 53us/step - loss: 0.1099 - acc: 0.9624 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 73/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1059 - acc: 0.9650 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 74/120\n",
      "7022/7022 [==============================] - 0s 56us/step - loss: 0.1114 - acc: 0.9613 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 75/120\n",
      "7022/7022 [==============================] - 0s 59us/step - loss: 0.1043 - acc: 0.9630 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 76/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1155 - acc: 0.9581 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 77/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0993 - acc: 0.9641 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 78/120\n",
      "7022/7022 [==============================] - 0s 58us/step - loss: 0.0994 - acc: 0.9682 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 79/120\n",
      "7022/7022 [==============================] - 0s 53us/step - loss: 0.0951 - acc: 0.9684 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 80/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.0919 - acc: 0.9697 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 81/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.0937 - acc: 0.9708 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 82/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0943 - acc: 0.9664 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 83/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0858 - acc: 0.9725 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 84/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0810 - acc: 0.9748 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 85/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0769 - acc: 0.9766 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 86/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0760 - acc: 0.9749 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 87/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0751 - acc: 0.9755 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 88/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0747 - acc: 0.9765 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 89/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0957 - acc: 0.9634 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 90/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.0932 - acc: 0.9662 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 91/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0765 - acc: 0.9756 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 92/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0635 - acc: 0.9816 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 93/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0757 - acc: 0.9756 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 94/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0630 - acc: 0.9809 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 95/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0678 - acc: 0.9781 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 96/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0586 - acc: 0.9833 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 97/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0664 - acc: 0.9791 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 98/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0545 - acc: 0.9842 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 99/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0576 - acc: 0.9828 - val_loss: 12.3996 - val_acc: 0.2307\n",
      "Epoch 100/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.0633 - acc: 0.9799 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 101/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0565 - acc: 0.9843 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 102/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0588 - acc: 0.9836 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 103/120\n",
      "7022/7022 [==============================] - 0s 54us/step - loss: 0.0555 - acc: 0.9819 - val_loss: 6.7054 - val_acc: 0.5836\n",
      "Epoch 104/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.0532 - acc: 0.9858 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 105/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0584 - acc: 0.9815 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 106/120\n",
      "7022/7022 [==============================] - 0s 59us/step - loss: 0.0537 - acc: 0.9838 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 107/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0613 - acc: 0.9792 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 108/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0533 - acc: 0.9826 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 109/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0628 - acc: 0.9813 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 110/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0634 - acc: 0.9801 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 111/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0483 - acc: 0.9859 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 112/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0384 - acc: 0.9909 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 113/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0338 - acc: 0.9939 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 114/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0425 - acc: 0.9882 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 115/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0411 - acc: 0.9893 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 116/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0511 - acc: 0.9865 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 117/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0494 - acc: 0.9838 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 118/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0393 - acc: 0.9902 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 119/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0421 - acc: 0.9870 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 120/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0500 - acc: 0.9853 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "3511/3511 [==============================] - 0s 14us/step\n",
      "7022/7022 [==============================] - 0s 14us/step\n",
      "Train on 7022 samples, validate on 3511 samples\n",
      "Epoch 1/120\n",
      "7022/7022 [==============================] - 1s 97us/step - loss: 0.4707 - acc: 0.8028 - val_loss: 12.3130 - val_acc: 0.2344\n",
      "Epoch 2/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.4397 - acc: 0.8142 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 3/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.4319 - acc: 0.8201 - val_loss: 4.8170 - val_acc: 0.6987\n",
      "Epoch 4/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.4220 - acc: 0.8190 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 5/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.4155 - acc: 0.8255 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 6/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.4108 - acc: 0.8246 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 7/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.4065 - acc: 0.8273 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 8/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.3999 - acc: 0.8308 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 9/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.3930 - acc: 0.8321 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 10/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.3880 - acc: 0.8347 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 11/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.3853 - acc: 0.8377 - val_loss: 3.7936 - val_acc: 0.7645\n",
      "Epoch 12/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.3794 - acc: 0.8382 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 13/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.3729 - acc: 0.8412 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 14/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3700 - acc: 0.8438 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 15/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.3647 - acc: 0.8424 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 16/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.3602 - acc: 0.8443 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 17/120\n",
      "7022/7022 [==============================] - 0s 44us/step - loss: 0.3525 - acc: 0.8516 - val_loss: 9.0780 - val_acc: 0.4332\n",
      "Epoch 18/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.3472 - acc: 0.8539 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 19/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.3406 - acc: 0.8597 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 20/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.3355 - acc: 0.8573 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 21/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.3325 - acc: 0.8603 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 22/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.3249 - acc: 0.8664 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 23/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.3213 - acc: 0.8680 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 24/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.3128 - acc: 0.8723 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 25/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.3087 - acc: 0.8704 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 26/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.2975 - acc: 0.8741 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 27/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.3012 - acc: 0.8752 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 28/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.2879 - acc: 0.8821 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 29/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.2844 - acc: 0.8827 - val_loss: 9.7464 - val_acc: 0.3936\n",
      "Epoch 30/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2797 - acc: 0.8842 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 31/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.2734 - acc: 0.8919 - val_loss: 12.3858 - val_acc: 0.2316\n",
      "Epoch 32/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.2670 - acc: 0.8921 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 33/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2595 - acc: 0.8948 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 34/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2531 - acc: 0.8952 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 35/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.2494 - acc: 0.8972 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 36/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.2420 - acc: 0.9019 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 37/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.2412 - acc: 0.9005 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 38/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2327 - acc: 0.9073 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 39/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.2341 - acc: 0.9073 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 40/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.2234 - acc: 0.9117 - val_loss: 5.5343 - val_acc: 0.6562\n",
      "Epoch 41/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.2160 - acc: 0.9151 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 42/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.2115 - acc: 0.9156 - val_loss: 12.3718 - val_acc: 0.2324\n",
      "Epoch 43/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2085 - acc: 0.9205 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 44/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.2038 - acc: 0.9217 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 45/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.2086 - acc: 0.9191 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 46/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.1990 - acc: 0.9244 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 47/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1896 - acc: 0.9251 - val_loss: 11.8797 - val_acc: 0.2626\n",
      "Epoch 48/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1864 - acc: 0.9336 - val_loss: 12.3996 - val_acc: 0.2307\n",
      "Epoch 49/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1805 - acc: 0.9338 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 50/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1778 - acc: 0.9305 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 51/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1694 - acc: 0.9381 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 52/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1718 - acc: 0.9369 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 53/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.1656 - acc: 0.9356 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 54/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1653 - acc: 0.9416 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 55/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1593 - acc: 0.9420 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 56/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1512 - acc: 0.9436 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 57/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1489 - acc: 0.9459 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 58/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1536 - acc: 0.9437 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 59/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1441 - acc: 0.9487 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 60/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1398 - acc: 0.9514 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 61/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1379 - acc: 0.9497 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 62/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.1332 - acc: 0.9531 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 63/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1405 - acc: 0.9489 - val_loss: 12.2071 - val_acc: 0.2424\n",
      "Epoch 64/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1335 - acc: 0.9524 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 65/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1292 - acc: 0.9543 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 66/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.1191 - acc: 0.9591 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 67/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1158 - acc: 0.9588 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 68/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1203 - acc: 0.9568 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 69/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.1108 - acc: 0.9613 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 70/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1102 - acc: 0.9638 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 71/120\n",
      "7022/7022 [==============================] - 0s 53us/step - loss: 0.1163 - acc: 0.9600 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 72/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1070 - acc: 0.9661 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 73/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.1047 - acc: 0.9624 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 74/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0998 - acc: 0.9664 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 75/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0969 - acc: 0.9678 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 76/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0929 - acc: 0.9695 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 77/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0911 - acc: 0.9697 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 78/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0859 - acc: 0.9728 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 79/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0914 - acc: 0.9674 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 80/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0883 - acc: 0.9715 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 81/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0930 - acc: 0.9658 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 82/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0899 - acc: 0.9682 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 83/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0781 - acc: 0.9749 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 84/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0782 - acc: 0.9745 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 85/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0770 - acc: 0.9762 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 86/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0752 - acc: 0.9759 - val_loss: 12.3454 - val_acc: 0.2336\n",
      "Epoch 87/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0822 - acc: 0.9735 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 88/120\n",
      "7022/7022 [==============================] - 0s 50us/step - loss: 0.0727 - acc: 0.9775 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 89/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0722 - acc: 0.9775 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 90/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0643 - acc: 0.9813 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 91/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0717 - acc: 0.9756 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 92/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0737 - acc: 0.9762 - val_loss: 3.7690 - val_acc: 0.7662\n",
      "Epoch 93/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0660 - acc: 0.9801 - val_loss: 12.3491 - val_acc: 0.2338\n",
      "Epoch 94/120\n",
      "7022/7022 [==============================] - 0s 51us/step - loss: 0.0891 - acc: 0.9744 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 95/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0707 - acc: 0.9778 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 96/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0543 - acc: 0.9856 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 97/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0646 - acc: 0.9792 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 98/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0555 - acc: 0.9833 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 99/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0493 - acc: 0.9869 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 100/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0464 - acc: 0.9883 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 101/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0468 - acc: 0.9876 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 102/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0525 - acc: 0.9870 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 103/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0914 - acc: 0.9681 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 104/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0638 - acc: 0.9799 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 105/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0576 - acc: 0.9826 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 106/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0476 - acc: 0.9882 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 107/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0448 - acc: 0.9892 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 108/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0341 - acc: 0.9927 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 109/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0420 - acc: 0.9892 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 110/120\n",
      "7022/7022 [==============================] - 0s 52us/step - loss: 0.0369 - acc: 0.9905 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 111/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0352 - acc: 0.9916 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 112/120\n",
      "7022/7022 [==============================] - 0s 49us/step - loss: 0.0371 - acc: 0.9905 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.1055 - acc: 0.9644 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 114/120\n",
      "7022/7022 [==============================] - 0s 45us/step - loss: 0.0748 - acc: 0.9756 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 115/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0411 - acc: 0.9903 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 116/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0346 - acc: 0.9929 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 117/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0276 - acc: 0.9953 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 118/120\n",
      "7022/7022 [==============================] - 0s 46us/step - loss: 0.0305 - acc: 0.9936 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 119/120\n",
      "7022/7022 [==============================] - 0s 48us/step - loss: 0.0297 - acc: 0.9943 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 120/120\n",
      "7022/7022 [==============================] - 0s 47us/step - loss: 0.0413 - acc: 0.9880 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "3511/3511 [==============================] - 0s 14us/step\n",
      "7022/7022 [==============================] - 0s 13us/step\n",
      "Train on 10533 samples, validate on 3511 samples\n",
      "Epoch 1/120\n",
      "10533/10533 [==============================] - 1s 82us/step - loss: 0.4690 - acc: 0.8011 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 2/120\n",
      "10533/10533 [==============================] - 0s 44us/step - loss: 0.4424 - acc: 0.8099 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 3/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.4328 - acc: 0.8153 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 4/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.4264 - acc: 0.8163 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 5/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.4215 - acc: 0.8192 - val_loss: 4.0775 - val_acc: 0.7462\n",
      "Epoch 6/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.4170 - acc: 0.8208 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 7/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.4123 - acc: 0.8225 - val_loss: 6.8470 - val_acc: 0.5722\n",
      "Epoch 8/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.4074 - acc: 0.8270 - val_loss: 6.1692 - val_acc: 0.6141\n",
      "Epoch 9/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.4047 - acc: 0.8268 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 10/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.4008 - acc: 0.8288 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 11/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.3946 - acc: 0.8320 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 12/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.3902 - acc: 0.8318 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 13/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.3882 - acc: 0.8330 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 14/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.3813 - acc: 0.8375 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 15/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3777 - acc: 0.8393 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 16/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3734 - acc: 0.8410 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 17/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.3676 - acc: 0.8418 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 18/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3618 - acc: 0.8454 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 19/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3583 - acc: 0.8465 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 20/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.3515 - acc: 0.8508 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 21/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3458 - acc: 0.8551 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 22/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3416 - acc: 0.8580 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 23/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.3370 - acc: 0.8572 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 24/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3333 - acc: 0.8599 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 25/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.3264 - acc: 0.8628 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 26/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.3227 - acc: 0.8650 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 27/120\n",
      "10533/10533 [==============================] - 1s 54us/step - loss: 0.3188 - acc: 0.8649 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 28/120\n",
      "10533/10533 [==============================] - 1s 50us/step - loss: 0.3115 - acc: 0.8694 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 29/120\n",
      "10533/10533 [==============================] - 1s 52us/step - loss: 0.3060 - acc: 0.8713 - val_loss: 3.9835 - val_acc: 0.7511\n",
      "Epoch 30/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.3015 - acc: 0.8745 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 31/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.2998 - acc: 0.8750 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 32/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.2921 - acc: 0.8804 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 33/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.2857 - acc: 0.8821 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 34/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.2825 - acc: 0.8825 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 35/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.2766 - acc: 0.8846 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 36/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.2720 - acc: 0.8874 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 37/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.2690 - acc: 0.8876 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 38/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.2648 - acc: 0.8916 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 39/120\n",
      "10533/10533 [==============================] - 0s 41us/step - loss: 0.2644 - acc: 0.8922 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 40/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.2545 - acc: 0.8967 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 41/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.2498 - acc: 0.8986 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 42/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.2470 - acc: 0.8986 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 43/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.2386 - acc: 0.9039 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 44/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.2362 - acc: 0.9053 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 45/120\n",
      "10533/10533 [==============================] - 0s 43us/step - loss: 0.2326 - acc: 0.9070 - val_loss: 12.3399 - val_acc: 0.2344\n",
      "Epoch 46/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.2252 - acc: 0.9118 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 47/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.2224 - acc: 0.9090 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 48/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.2236 - acc: 0.9101 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 49/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.2141 - acc: 0.9124 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 50/120\n",
      "10533/10533 [==============================] - 1s 50us/step - loss: 0.2076 - acc: 0.9184 - val_loss: 3.7782 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.2049 - acc: 0.9183 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 52/120\n",
      "10533/10533 [==============================] - 1s 50us/step - loss: 0.2062 - acc: 0.9168 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 53/120\n",
      "10533/10533 [==============================] - 1s 51us/step - loss: 0.2014 - acc: 0.9199 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 54/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1945 - acc: 0.9240 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 55/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.1903 - acc: 0.9277 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 56/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1911 - acc: 0.9249 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 57/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1838 - acc: 0.9304 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 58/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1814 - acc: 0.9285 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 59/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1745 - acc: 0.9315 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 60/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1722 - acc: 0.9311 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 61/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1723 - acc: 0.9341 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 62/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1651 - acc: 0.9367 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 63/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.1612 - acc: 0.9373 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 64/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.1626 - acc: 0.9368 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 65/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1570 - acc: 0.9387 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 66/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1555 - acc: 0.9391 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 67/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.1539 - acc: 0.9428 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 68/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.1452 - acc: 0.9445 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 69/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.1481 - acc: 0.9434 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 70/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1445 - acc: 0.9444 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 71/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1393 - acc: 0.9480 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 72/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1350 - acc: 0.9508 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 73/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1342 - acc: 0.9508 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 74/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1276 - acc: 0.9521 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 75/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1297 - acc: 0.9515 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 76/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.1277 - acc: 0.9512 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 77/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1234 - acc: 0.9536 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 78/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.1184 - acc: 0.9562 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 79/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1227 - acc: 0.9553 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 80/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.1162 - acc: 0.9576 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 81/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.1132 - acc: 0.9601 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 82/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.1072 - acc: 0.9621 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 83/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1082 - acc: 0.9614 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 84/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1094 - acc: 0.9594 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 85/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.1015 - acc: 0.9642 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 86/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.1050 - acc: 0.9630 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 87/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.0983 - acc: 0.9659 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 88/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.0976 - acc: 0.9668 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 89/120\n",
      "10533/10533 [==============================] - 1s 54us/step - loss: 0.0919 - acc: 0.9692 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 90/120\n",
      "10533/10533 [==============================] - 1s 54us/step - loss: 0.0936 - acc: 0.9690 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 91/120\n",
      "10533/10533 [==============================] - 1s 50us/step - loss: 0.0906 - acc: 0.9690 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 92/120\n",
      "10533/10533 [==============================] - 1s 49us/step - loss: 0.1003 - acc: 0.9658 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 93/120\n",
      "10533/10533 [==============================] - 1s 51us/step - loss: 0.1051 - acc: 0.9633 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 94/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.0829 - acc: 0.9717 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 95/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.0787 - acc: 0.9750 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 96/120\n",
      "10533/10533 [==============================] - 1s 53us/step - loss: 0.0780 - acc: 0.9749 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 97/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.0812 - acc: 0.9721 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 98/120\n",
      "10533/10533 [==============================] - 0s 44us/step - loss: 0.1073 - acc: 0.9606 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 99/120\n",
      "10533/10533 [==============================] - 0s 44us/step - loss: 0.0744 - acc: 0.9760 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 100/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.0883 - acc: 0.9692 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 101/120\n",
      "10533/10533 [==============================] - 0s 44us/step - loss: 0.0703 - acc: 0.9762 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 102/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.0697 - acc: 0.9774 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 103/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.0721 - acc: 0.9756 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 104/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.0686 - acc: 0.9772 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 105/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.0678 - acc: 0.9785 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 106/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.0868 - acc: 0.9711 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 107/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.0736 - acc: 0.9743 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 108/120\n",
      "10533/10533 [==============================] - 1s 50us/step - loss: 0.0606 - acc: 0.9810 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 109/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.0597 - acc: 0.9813 - val_loss: 3.7782 - val_acc: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/120\n",
      "10533/10533 [==============================] - 0s 47us/step - loss: 0.0638 - acc: 0.9789 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 111/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.0640 - acc: 0.9803 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 112/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.0725 - acc: 0.9747 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 113/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.0666 - acc: 0.9781 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 114/120\n",
      "10533/10533 [==============================] - 1s 56us/step - loss: 0.0557 - acc: 0.9823 - val_loss: 3.7736 - val_acc: 0.7659\n",
      "Epoch 115/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.0612 - acc: 0.9823 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 116/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.0636 - acc: 0.9785 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 117/120\n",
      "10533/10533 [==============================] - 0s 46us/step - loss: 0.0603 - acc: 0.9806 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 118/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.0534 - acc: 0.9838 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 119/120\n",
      "10533/10533 [==============================] - 0s 45us/step - loss: 0.0523 - acc: 0.9846 - val_loss: 3.7782 - val_acc: 0.7656\n",
      "Epoch 120/120\n",
      "10533/10533 [==============================] - 1s 48us/step - loss: 0.0455 - acc: 0.9856 - val_loss: 3.7782 - val_acc: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x1229417f0>,\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'dense_layer_sizes': [[110, 110]], 'epochs': [120], 'activation': ['relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_size_candidates = [[110, 110]]\n",
    "classifier = KerasClassifier(make_model)\n",
    "validator = GridSearchCV(classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     'epochs': [120],\n",
    "                                     'activation': ['relu'],\n",
    "                                    }, n_jobs=1)\n",
    "validator.fit(X_train_scaled, y_train_categorical, validation_data=(X_test, y_test_categorical))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters of the best model are: \n",
      "{'activation': 'relu', 'dense_layer_sizes': [110, 110], 'epochs': 120}\n",
      "0.7719548087191132\n"
     ]
    }
   ],
   "source": [
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)\n",
    "print(validator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3511/3511 [==============================] - 0s 19us/step\n",
      "loss :  1.2409757625951416\n",
      "acc :  0.768157220317984\n"
     ]
    }
   ],
   "source": [
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(X_test_scaled, y_test_categorical)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join('..', 'model', 'grammy_prediction_model.h5')\n",
    "best_model.save(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Acousticness', 'Danceability', 'Duration (ms)', 'Energy',\n",
       "       'Instrumentalness', 'Liveness', 'Loudness', 'Mode', 'Speechiness',\n",
       "       'Tempo', 'Time Signature', 'Valence', 'Explicit', 'Popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/grammy_prediction_scaler.sav']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "scaler_file = os.path.join('..', 'model', 'grammy_prediction_scaler.sav')\n",
    "joblib.dump(X_scaler, scaler_file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
