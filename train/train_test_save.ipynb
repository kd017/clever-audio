{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINED_DATA = os.path.join('..', 'data', 'combined-data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>TrackId</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Album</th>\n",
       "      <th>Image</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Preview</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958</td>\n",
       "      <td>Domenico Modugno</td>\n",
       "      <td>Nel Blu Dipinto Di Blu (Volare)</td>\n",
       "      <td>https://open.spotify.com/track/006Ndmw2hHxvnLb...</td>\n",
       "      <td>006Ndmw2hHxvnLbJsBFnPx</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>Tutto Modugno (Mister Volare)</td>\n",
       "      <td>https://i.scdn.co/image/5e8c49f7a8d161c1d65109...</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/a0e2ef35a1613d86...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1958</td>\n",
       "      <td>Henry Mancini</td>\n",
       "      <td>The Music From Peter Gunn</td>\n",
       "      <td>https://open.spotify.com/track/3BdPP6Xce6FUcfa...</td>\n",
       "      <td>3BdPP6Xce6FUcfaCFsnZIg</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.550</td>\n",
       "      <td>177733.0</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>138.037</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>The music from Peter Gunn</td>\n",
       "      <td>https://i.scdn.co/image/1ad2e8ce1f988c27678298...</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/8380c4830866fc12...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1958</td>\n",
       "      <td>Domenico Modugno, songwriter (Domenico Modugno)</td>\n",
       "      <td>Nel Blu Dipinto Di Blu (Volare)</td>\n",
       "      <td>https://open.spotify.com/track/006Ndmw2hHxvnLb...</td>\n",
       "      <td>006Ndmw2hHxvnLbJsBFnPx</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>Tutto Modugno (Mister Volare)</td>\n",
       "      <td>https://i.scdn.co/image/5e8c49f7a8d161c1d65109...</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/a0e2ef35a1613d86...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>Perry Como</td>\n",
       "      <td>Catch A Falling Star</td>\n",
       "      <td>https://open.spotify.com/track/38YMdelhj62vJ6d...</td>\n",
       "      <td>38YMdelhj62vJ6d5a0wxMQ</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.628</td>\n",
       "      <td>148493.0</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>118.895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.475</td>\n",
       "      <td>It's Impossible</td>\n",
       "      <td>https://i.scdn.co/image/0a33dd0dbd1b416c245c8c...</td>\n",
       "      <td>False</td>\n",
       "      <td>44.0</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/9e2cfff3559c2e26...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>The Champs</td>\n",
       "      <td>Tequila</td>\n",
       "      <td>https://open.spotify.com/track/5gJKsGij5oGt5H5...</td>\n",
       "      <td>5gJKsGij5oGt5H5RSFYXPa</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.671</td>\n",
       "      <td>135240.0</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>89.748</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.897</td>\n",
       "      <td>Greatest Hits / Tequila</td>\n",
       "      <td>https://i.scdn.co/image/f969d6a06169034bc57193...</td>\n",
       "      <td>False</td>\n",
       "      <td>58.0</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/2c88f827c751d5e5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                           Artist  \\\n",
       "0  1958                                 Domenico Modugno   \n",
       "1  1958                                    Henry Mancini   \n",
       "2  1958  Domenico Modugno, songwriter (Domenico Modugno)   \n",
       "3  1958                                       Perry Como   \n",
       "4  1958                                       The Champs   \n",
       "\n",
       "                             Title  \\\n",
       "0  Nel Blu Dipinto Di Blu (Volare)   \n",
       "1        The Music From Peter Gunn   \n",
       "2  Nel Blu Dipinto Di Blu (Volare)   \n",
       "3             Catch A Falling Star   \n",
       "4                          Tequila   \n",
       "\n",
       "                                                 URL                 TrackId  \\\n",
       "0  https://open.spotify.com/track/006Ndmw2hHxvnLb...  006Ndmw2hHxvnLbJsBFnPx   \n",
       "1  https://open.spotify.com/track/3BdPP6Xce6FUcfa...  3BdPP6Xce6FUcfaCFsnZIg   \n",
       "2  https://open.spotify.com/track/006Ndmw2hHxvnLb...  006Ndmw2hHxvnLbJsBFnPx   \n",
       "3  https://open.spotify.com/track/38YMdelhj62vJ6d...  38YMdelhj62vJ6d5a0wxMQ   \n",
       "4  https://open.spotify.com/track/5gJKsGij5oGt5H5...  5gJKsGij5oGt5H5RSFYXPa   \n",
       "\n",
       "   Acousticness  Danceability  Duration (ms)  Energy  Instrumentalness  ...    \\\n",
       "0         0.987         0.518       216373.0   0.060          0.000008  ...     \n",
       "1         0.893         0.550       177733.0   0.318          0.881000  ...     \n",
       "2         0.987         0.518       216373.0   0.060          0.000008  ...     \n",
       "3         0.864         0.628       148493.0   0.172          0.000000  ...     \n",
       "4         0.121         0.671       135240.0   0.742          0.679000  ...     \n",
       "\n",
       "   Speechiness    Tempo  Time Signature  Valence  \\\n",
       "0       0.0441  127.870             4.0    0.336   \n",
       "1       0.0313  138.037             4.0    0.620   \n",
       "2       0.0441  127.870             4.0    0.336   \n",
       "3       0.0600  118.895             3.0    0.475   \n",
       "4       0.0441   89.748             4.0    0.897   \n",
       "\n",
       "                           Album  \\\n",
       "0  Tutto Modugno (Mister Volare)   \n",
       "1      The music from Peter Gunn   \n",
       "2  Tutto Modugno (Mister Volare)   \n",
       "3                It's Impossible   \n",
       "4        Greatest Hits / Tequila   \n",
       "\n",
       "                                               Image  Explicit  Popularity  \\\n",
       "0  https://i.scdn.co/image/5e8c49f7a8d161c1d65109...     False        34.0   \n",
       "1  https://i.scdn.co/image/1ad2e8ce1f988c27678298...     False        16.0   \n",
       "2  https://i.scdn.co/image/5e8c49f7a8d161c1d65109...     False        34.0   \n",
       "3  https://i.scdn.co/image/0a33dd0dbd1b416c245c8c...     False        44.0   \n",
       "4  https://i.scdn.co/image/f969d6a06169034bc57193...     False        58.0   \n",
       "\n",
       "                                             Preview Winner  \n",
       "0  https://p.scdn.co/mp3-preview/a0e2ef35a1613d86...      1  \n",
       "1  https://p.scdn.co/mp3-preview/8380c4830866fc12...      1  \n",
       "2  https://p.scdn.co/mp3-preview/a0e2ef35a1613d86...      1  \n",
       "3  https://p.scdn.co/mp3-preview/9e2cfff3559c2e26...      1  \n",
       "4  https://p.scdn.co/mp3-preview/2c88f827c751d5e5...      1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df = pd.read_csv(COMBINED_DATA)\n",
    "songs_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df = songs_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Artist', 'Title', 'URL', 'TrackId', 'Acousticness',\n",
       "       'Danceability', 'Duration (ms)', 'Energy', 'Instrumentalness', 'Key',\n",
       "       'Liveness', 'Loudness', 'Mode', 'Speechiness', 'Tempo',\n",
       "       'Time Signature', 'Valence', 'Album', 'Image', 'Explicit', 'Popularity',\n",
       "       'Preview', 'Winner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.00427</td>\n",
       "      <td>0.762</td>\n",
       "      <td>232093.0</td>\n",
       "      <td>0.6660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127</td>\n",
       "      <td>-6.055</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>118.970</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.278</td>\n",
       "      <td>True</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1974</td>\n",
       "      <td>0.00878</td>\n",
       "      <td>0.504</td>\n",
       "      <td>386707.0</td>\n",
       "      <td>0.7190</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-9.155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>102.144</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.177</td>\n",
       "      <td>False</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.85400</td>\n",
       "      <td>0.210</td>\n",
       "      <td>185080.0</td>\n",
       "      <td>0.0959</td>\n",
       "      <td>0.003550</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>-17.767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>175.914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.167</td>\n",
       "      <td>False</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1974</td>\n",
       "      <td>0.25500</td>\n",
       "      <td>0.488</td>\n",
       "      <td>296133.0</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>-9.878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>135.093</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>False</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.04060</td>\n",
       "      <td>0.353</td>\n",
       "      <td>287560.0</td>\n",
       "      <td>0.5720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.967</td>\n",
       "      <td>-6.878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>176.086</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.133</td>\n",
       "      <td>False</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Acousticness  Danceability  Duration (ms)  Energy  Instrumentalness  \\\n",
       "0  2016       0.00427         0.762       232093.0  0.6660          0.000000   \n",
       "1  1974       0.00878         0.504       386707.0  0.7190          0.001490   \n",
       "2  2017       0.85400         0.210       185080.0  0.0959          0.003550   \n",
       "3  1974       0.25500         0.488       296133.0  0.4930          0.000181   \n",
       "4  2006       0.04060         0.353       287560.0  0.5720          0.000000   \n",
       "\n",
       "    Key  Liveness  Loudness  Mode  Speechiness    Tempo  Time Signature  \\\n",
       "0   0.0     0.127    -6.055   1.0       0.0916  118.970             4.0   \n",
       "1   1.0     0.075    -9.155   0.0       0.0431  102.144             4.0   \n",
       "2   5.0     0.261   -17.767   1.0       0.0347  175.914             3.0   \n",
       "3   2.0     0.102    -9.878   1.0       0.0464  135.093             4.0   \n",
       "4  11.0     0.967    -6.878   1.0       0.0362  176.086             4.0   \n",
       "\n",
       "   Valence  Explicit  Popularity  \n",
       "0    0.278      True        69.0  \n",
       "1    0.177     False        63.0  \n",
       "2    0.167     False        53.0  \n",
       "3    0.389     False        50.0  \n",
       "4    0.133     False        40.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = songs_df.drop(labels=['Artist', 'Title', 'URL', 'TrackId', 'Album', 'Image', 'Winner', 'Preview'], axis=1)\n",
    "X = X[['Year', 'Acousticness', 'Danceability', 'Duration (ms)', 'Energy',\n",
    "       'Instrumentalness', 'Key', 'Liveness', 'Loudness', 'Mode',\n",
    "       'Speechiness', 'Tempo', 'Time Signature', 'Valence', 'Explicit',\n",
    "       'Popularity']]\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                  int64\n",
       "Acousticness        float64\n",
       "Danceability        float64\n",
       "Duration (ms)       float64\n",
       "Energy              float64\n",
       "Instrumentalness    float64\n",
       "Key                 float64\n",
       "Liveness            float64\n",
       "Loudness            float64\n",
       "Mode                float64\n",
       "Speechiness         float64\n",
       "Tempo               float64\n",
       "Time Signature      float64\n",
       "Valence             float64\n",
       "Explicit               bool\n",
       "Popularity          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Explicit'] = X.Explicit.astype(int)\n",
    "X['Year'] = X.Explicit.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8285\n",
       "1     606\n",
       "Name: Explicit, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.Explicit.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluded_features = ['Year', 'Key']\n",
    "X.drop(labels=excluded_features, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = songs_df['Winner']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6729\n",
       "1    2162\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/ipykernel_launcher.py:11: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/ipykernel_launcher.py:13: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.3, stratify=y)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.3, random_state=1, stratify=y_train)\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "\n",
    "# Convert labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "y_val_categorical = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8891, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dims = len(X.columns)\n",
    "# Create model and add layers\n",
    "def make_model(dense_layer_sizes, activation, optimizer):\n",
    "    model = Sequential()\n",
    "    for dense_layer in dense_layer_sizes:\n",
    "        model.add(Dense(units=dense_layer, activation=activation, input_dim=dims))\n",
    "        \n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2904 samples, validate on 1867 samples\n",
      "Epoch 1/250\n",
      "2904/2904 [==============================] - 0s 101us/step - loss: 0.5564 - acc: 0.7683 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 2/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4965 - acc: 0.7920 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 3/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4866 - acc: 0.7948 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 4/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.4775 - acc: 0.8017 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 5/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4722 - acc: 0.8030 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 6/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4673 - acc: 0.8051 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 7/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.4618 - acc: 0.8051 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 8/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4576 - acc: 0.8051 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 9/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4536 - acc: 0.8054 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 10/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4481 - acc: 0.8092 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 11/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4443 - acc: 0.8092 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 12/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4451 - acc: 0.8103 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 13/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4372 - acc: 0.8106 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 14/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4336 - acc: 0.8134 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 15/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4284 - acc: 0.8140 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 16/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4262 - acc: 0.8151 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 17/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4223 - acc: 0.8140 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 18/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4204 - acc: 0.8171 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 19/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4152 - acc: 0.8202 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 20/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4108 - acc: 0.8206 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 21/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4088 - acc: 0.8230 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 22/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4040 - acc: 0.8261 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 23/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3992 - acc: 0.8285 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 24/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3970 - acc: 0.8289 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 25/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3918 - acc: 0.8316 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 26/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3895 - acc: 0.8357 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 27/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3877 - acc: 0.8333 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 28/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3828 - acc: 0.8392 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 29/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3772 - acc: 0.8378 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 30/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3741 - acc: 0.8399 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 31/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.3718 - acc: 0.8447 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 32/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3663 - acc: 0.8457 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 33/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3640 - acc: 0.8475 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 34/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3635 - acc: 0.8492 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 35/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3554 - acc: 0.8526 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 36/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3540 - acc: 0.8516 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 37/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3497 - acc: 0.8571 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 38/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3475 - acc: 0.8557 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 39/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3425 - acc: 0.8605 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 40/250\n",
      "2904/2904 [==============================] - 0s 10us/step - loss: 0.3395 - acc: 0.8543 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 41/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3351 - acc: 0.8671 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 42/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3290 - acc: 0.8643 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 43/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3296 - acc: 0.8674 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 44/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3233 - acc: 0.8688 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 45/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3217 - acc: 0.8750 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 46/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3154 - acc: 0.8743 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 47/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3137 - acc: 0.8771 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 48/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3105 - acc: 0.8747 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 49/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3054 - acc: 0.8791 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 50/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3014 - acc: 0.8877 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 51/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3002 - acc: 0.8781 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 52/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2954 - acc: 0.8850 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 53/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2908 - acc: 0.8895 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 54/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2875 - acc: 0.8946 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 55/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2839 - acc: 0.8857 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 56/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2816 - acc: 0.8908 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 57/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2823 - acc: 0.8905 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 58/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2846 - acc: 0.8895 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 59/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2760 - acc: 0.8908 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2815 - acc: 0.8953 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 61/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2678 - acc: 0.9056 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 62/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2602 - acc: 0.9043 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 63/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2618 - acc: 0.9001 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 64/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2564 - acc: 0.9053 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 65/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2541 - acc: 0.9087 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 66/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2554 - acc: 0.9036 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 67/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2505 - acc: 0.9084 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 68/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2456 - acc: 0.9108 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 69/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2425 - acc: 0.9149 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 70/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2457 - acc: 0.9077 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 71/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2362 - acc: 0.9180 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 72/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2375 - acc: 0.9112 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 73/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2323 - acc: 0.9167 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 74/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.2242 - acc: 0.9211 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 75/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2249 - acc: 0.9229 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 76/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2268 - acc: 0.9201 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 77/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2171 - acc: 0.9246 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 78/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2156 - acc: 0.9232 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 79/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2135 - acc: 0.9260 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 80/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2130 - acc: 0.9298 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 81/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2090 - acc: 0.9291 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 82/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2070 - acc: 0.9291 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 83/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2078 - acc: 0.9256 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 84/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2046 - acc: 0.9280 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 85/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2001 - acc: 0.9308 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 86/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1972 - acc: 0.9349 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 87/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1963 - acc: 0.9346 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 88/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1876 - acc: 0.9370 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 89/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1860 - acc: 0.9370 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 90/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1867 - acc: 0.9408 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 91/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1821 - acc: 0.9418 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 92/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1782 - acc: 0.9446 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 93/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.1784 - acc: 0.9411 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 94/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1756 - acc: 0.9432 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 95/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1721 - acc: 0.9459 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 96/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1732 - acc: 0.9435 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 97/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1674 - acc: 0.9466 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 98/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1649 - acc: 0.9459 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 99/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1643 - acc: 0.9463 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 100/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1615 - acc: 0.9504 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 101/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1585 - acc: 0.9494 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 102/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1541 - acc: 0.9559 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 103/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1522 - acc: 0.9552 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 104/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1536 - acc: 0.9497 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 105/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1487 - acc: 0.9539 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 106/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1477 - acc: 0.9570 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 107/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1445 - acc: 0.9563 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 108/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1440 - acc: 0.9570 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 109/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1419 - acc: 0.9580 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 110/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1469 - acc: 0.9573 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 111/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1463 - acc: 0.9521 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 112/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1505 - acc: 0.9552 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 113/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1478 - acc: 0.9514 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 114/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1439 - acc: 0.9566 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 115/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1329 - acc: 0.9590 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 116/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1348 - acc: 0.9628 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 117/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1288 - acc: 0.9656 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 118/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1261 - acc: 0.9656 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 119/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1244 - acc: 0.9638 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 120/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1196 - acc: 0.9669 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 121/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1205 - acc: 0.9666 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 122/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1226 - acc: 0.9652 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 123/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1207 - acc: 0.9649 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 124/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1166 - acc: 0.9690 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 125/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1135 - acc: 0.9707 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 126/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1126 - acc: 0.9718 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 127/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1179 - acc: 0.9669 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 128/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1140 - acc: 0.9652 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 129/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1114 - acc: 0.9694 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 130/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1096 - acc: 0.9704 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 131/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1122 - acc: 0.9697 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 132/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1024 - acc: 0.9735 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 133/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1044 - acc: 0.9749 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 134/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1051 - acc: 0.9742 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 135/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1056 - acc: 0.9704 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 136/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0998 - acc: 0.9773 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 137/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1016 - acc: 0.9718 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 138/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0979 - acc: 0.9759 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 139/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0988 - acc: 0.9749 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 140/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0977 - acc: 0.9759 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 141/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0944 - acc: 0.9766 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 142/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0945 - acc: 0.9735 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 143/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0951 - acc: 0.9790 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 144/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1022 - acc: 0.9718 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 145/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1053 - acc: 0.9721 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 146/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0915 - acc: 0.9745 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 147/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0959 - acc: 0.9783 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 148/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0900 - acc: 0.9783 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 149/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0872 - acc: 0.9814 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 150/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0889 - acc: 0.9783 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 151/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0863 - acc: 0.9811 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 152/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0805 - acc: 0.9811 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 153/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0860 - acc: 0.9797 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 154/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0833 - acc: 0.9821 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 155/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0815 - acc: 0.9800 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 156/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0779 - acc: 0.9811 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 157/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0751 - acc: 0.9817 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 158/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0752 - acc: 0.9869 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 159/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0745 - acc: 0.9859 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 160/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0737 - acc: 0.9848 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 161/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0765 - acc: 0.9848 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 162/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0746 - acc: 0.9835 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 163/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0702 - acc: 0.9866 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 164/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0687 - acc: 0.9876 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 165/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0707 - acc: 0.9855 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 166/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0676 - acc: 0.9876 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 167/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0679 - acc: 0.9873 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 168/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0666 - acc: 0.9855 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 169/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0669 - acc: 0.9873 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 170/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0657 - acc: 0.9862 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 171/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0671 - acc: 0.9852 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 172/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0639 - acc: 0.9900 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 173/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0622 - acc: 0.9893 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 174/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0609 - acc: 0.9893 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 175/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0591 - acc: 0.9917 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 176/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0614 - acc: 0.9900 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 177/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0625 - acc: 0.9883 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 178/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0594 - acc: 0.9883 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 179/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0572 - acc: 0.9904 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 180/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0594 - acc: 0.9897 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 181/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0571 - acc: 0.9873 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 182/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0552 - acc: 0.9921 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 183/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0556 - acc: 0.9900 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 184/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0550 - acc: 0.9917 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 185/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0539 - acc: 0.9904 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 186/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0538 - acc: 0.9907 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 187/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0527 - acc: 0.9924 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 188/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0517 - acc: 0.9924 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 189/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0521 - acc: 0.9914 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 190/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0523 - acc: 0.9904 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 191/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0480 - acc: 0.9941 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 192/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0498 - acc: 0.9917 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 193/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0499 - acc: 0.9928 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 194/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0489 - acc: 0.9917 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 195/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0488 - acc: 0.9914 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 196/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0538 - acc: 0.9890 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 197/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0498 - acc: 0.9914 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 198/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0502 - acc: 0.9924 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 199/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0456 - acc: 0.9924 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 200/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0471 - acc: 0.9928 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 201/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0454 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 202/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0468 - acc: 0.9921 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 203/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0433 - acc: 0.9931 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 204/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0437 - acc: 0.9931 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 205/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0431 - acc: 0.9935 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 206/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0428 - acc: 0.9938 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 207/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0409 - acc: 0.9941 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 208/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0396 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 209/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0406 - acc: 0.9941 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 210/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0397 - acc: 0.9948 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 211/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0404 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 212/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0421 - acc: 0.9941 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 213/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0403 - acc: 0.9935 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 214/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0395 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 215/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0359 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 216/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0365 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 217/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0373 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 218/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0384 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 219/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0360 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 220/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0341 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 221/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0346 - acc: 0.9955 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 222/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0326 - acc: 0.9966 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 223/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0326 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 224/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0335 - acc: 0.9966 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 225/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0341 - acc: 0.9955 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 226/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0318 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 227/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0329 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 228/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0344 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 229/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0334 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 230/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0322 - acc: 0.9962 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 231/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0343 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 232/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0365 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 233/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0389 - acc: 0.9928 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 234/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0316 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 235/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0318 - acc: 0.9955 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 236/250\n",
      "2904/2904 [==============================] - 0s 19us/step - loss: 0.0299 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 237/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0287 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 238/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0279 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 239/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0293 - acc: 0.9969 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 240/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0287 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 241/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0278 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 242/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0268 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 243/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0254 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 244/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0246 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 245/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0249 - acc: 0.9983 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 246/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0252 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 247/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0245 - acc: 0.9990 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 248/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0241 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 249/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0244 - acc: 0.9983 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 250/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0243 - acc: 0.9990 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "1452/1452 [==============================] - 0s 15us/step\n",
      "2904/2904 [==============================] - 0s 14us/step\n",
      "Train on 2904 samples, validate on 1867 samples\n",
      "Epoch 1/250\n",
      "2904/2904 [==============================] - 0s 118us/step - loss: 0.5785 - acc: 0.7417 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 2/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.5054 - acc: 0.7903 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 3/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4882 - acc: 0.7989 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 4/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4804 - acc: 0.8037 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 5/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4720 - acc: 0.8020 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 6/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4654 - acc: 0.8061 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 7/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4603 - acc: 0.8075 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 8/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4547 - acc: 0.8089 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 9/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4485 - acc: 0.8113 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 10/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4439 - acc: 0.8120 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 11/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4392 - acc: 0.8137 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 12/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4369 - acc: 0.8147 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 13/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4301 - acc: 0.8158 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 14/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4270 - acc: 0.8154 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 15/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4228 - acc: 0.8227 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 16/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4172 - acc: 0.8206 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 17/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4151 - acc: 0.8237 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 18/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.4099 - acc: 0.8264 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 19/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.4062 - acc: 0.8285 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 20/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4019 - acc: 0.8278 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 21/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.3988 - acc: 0.8292 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 22/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.3938 - acc: 0.8326 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 23/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3917 - acc: 0.8326 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 24/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3890 - acc: 0.8364 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 25/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3872 - acc: 0.8347 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 26/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3837 - acc: 0.8364 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 27/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3794 - acc: 0.8402 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 28/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3772 - acc: 0.8375 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 29/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3730 - acc: 0.8426 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 30/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3676 - acc: 0.8444 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 31/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3628 - acc: 0.8447 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 32/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3586 - acc: 0.8464 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 33/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3532 - acc: 0.8540 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 34/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3518 - acc: 0.8537 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 35/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3472 - acc: 0.8540 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 36/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3493 - acc: 0.8557 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 37/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3445 - acc: 0.8519 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 38/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3418 - acc: 0.8598 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 39/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3372 - acc: 0.8633 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 40/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3320 - acc: 0.8629 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 41/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3303 - acc: 0.8626 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 42/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3274 - acc: 0.8664 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 43/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3222 - acc: 0.8709 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 44/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3238 - acc: 0.8667 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 45/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3147 - acc: 0.8729 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 46/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.3114 - acc: 0.8722 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 47/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3076 - acc: 0.8771 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 48/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3023 - acc: 0.8812 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 49/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3028 - acc: 0.8764 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 50/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3046 - acc: 0.8771 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 51/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2969 - acc: 0.8853 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 52/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2943 - acc: 0.8840 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 53/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2984 - acc: 0.8826 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 54/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2869 - acc: 0.8908 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 55/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2802 - acc: 0.8926 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 56/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2816 - acc: 0.8902 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 57/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2820 - acc: 0.8864 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 58/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2783 - acc: 0.8902 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 59/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2740 - acc: 0.8915 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 60/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2669 - acc: 0.9008 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 61/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2636 - acc: 0.8991 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 62/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2610 - acc: 0.9029 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 63/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2600 - acc: 0.9050 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 64/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2558 - acc: 0.9005 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 65/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2511 - acc: 0.9056 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 66/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2517 - acc: 0.9053 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 67/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2447 - acc: 0.9105 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 68/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2441 - acc: 0.9087 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 69/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2419 - acc: 0.9098 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 70/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2394 - acc: 0.9115 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 71/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2333 - acc: 0.9177 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 72/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2304 - acc: 0.9160 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 73/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2264 - acc: 0.9194 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 74/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2287 - acc: 0.9167 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 75/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2225 - acc: 0.9198 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 76/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2239 - acc: 0.9191 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 77/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2192 - acc: 0.9249 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 78/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2145 - acc: 0.9222 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 79/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2119 - acc: 0.9256 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 80/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2067 - acc: 0.9284 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 81/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2047 - acc: 0.9277 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 82/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2046 - acc: 0.9318 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 83/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2012 - acc: 0.9287 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 84/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2013 - acc: 0.9335 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 85/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1988 - acc: 0.9284 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 86/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1935 - acc: 0.9342 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 87/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1881 - acc: 0.9353 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 88/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1886 - acc: 0.9366 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 89/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1854 - acc: 0.9380 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 90/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1833 - acc: 0.9394 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 91/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1798 - acc: 0.9404 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 92/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1790 - acc: 0.9452 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 93/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1756 - acc: 0.9456 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 94/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1781 - acc: 0.9418 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 95/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1712 - acc: 0.9415 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 96/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1713 - acc: 0.9449 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 97/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1663 - acc: 0.9528 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 98/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1645 - acc: 0.9456 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 99/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1617 - acc: 0.9497 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 100/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1654 - acc: 0.9466 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 101/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1605 - acc: 0.9487 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 102/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1558 - acc: 0.9549 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 103/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.1559 - acc: 0.9514 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 104/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1536 - acc: 0.9552 - val_loss: 12.1900 - val_acc: 0.2437\n",
      "Epoch 105/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.1511 - acc: 0.9508 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 106/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1487 - acc: 0.9549 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 107/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.1463 - acc: 0.9552 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 108/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1451 - acc: 0.9573 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 109/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1433 - acc: 0.9566 - val_loss: 12.1814 - val_acc: 0.2442\n",
      "Epoch 110/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1428 - acc: 0.9563 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 111/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1426 - acc: 0.9566 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 112/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.1400 - acc: 0.9563 - val_loss: 11.5985 - val_acc: 0.2758\n",
      "Epoch 113/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1375 - acc: 0.9587 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 114/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1304 - acc: 0.9656 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 115/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1320 - acc: 0.9625 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 116/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1284 - acc: 0.9642 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 117/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1284 - acc: 0.9618 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 118/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1252 - acc: 0.9659 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 119/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1267 - acc: 0.9618 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 120/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1254 - acc: 0.9628 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 121/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1212 - acc: 0.9669 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 122/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1217 - acc: 0.9597 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 123/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1167 - acc: 0.9666 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 124/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1188 - acc: 0.9673 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 125/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1179 - acc: 0.9687 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 126/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1151 - acc: 0.9711 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 127/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1151 - acc: 0.9669 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 128/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1108 - acc: 0.9694 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 129/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1137 - acc: 0.9628 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 130/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1181 - acc: 0.9669 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 131/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.1155 - acc: 0.9628 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 132/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.1112 - acc: 0.9707 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 133/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1076 - acc: 0.9718 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 134/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1127 - acc: 0.9663 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 135/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1074 - acc: 0.9666 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 136/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1020 - acc: 0.9742 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 137/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0987 - acc: 0.9773 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 138/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0998 - acc: 0.9725 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 139/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0983 - acc: 0.9752 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 140/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0940 - acc: 0.9773 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 141/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0935 - acc: 0.9762 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 142/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0912 - acc: 0.9773 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 143/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0889 - acc: 0.9790 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 144/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0872 - acc: 0.9807 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 145/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0870 - acc: 0.9773 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 146/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0877 - acc: 0.9807 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 147/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0860 - acc: 0.9807 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 148/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0835 - acc: 0.9821 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 149/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0816 - acc: 0.9824 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 150/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0823 - acc: 0.9804 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 151/250\n",
      "2904/2904 [==============================] - 0s 19us/step - loss: 0.0868 - acc: 0.9793 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 152/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0823 - acc: 0.9811 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 153/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0825 - acc: 0.9824 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 154/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0814 - acc: 0.9838 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 155/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0789 - acc: 0.9811 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 156/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0775 - acc: 0.9828 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 157/250\n",
      "2904/2904 [==============================] - 0s 19us/step - loss: 0.0743 - acc: 0.9838 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 158/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0733 - acc: 0.9838 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 159/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0744 - acc: 0.9845 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 160/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0724 - acc: 0.9842 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 161/250\n",
      "2904/2904 [==============================] - 0s 19us/step - loss: 0.0740 - acc: 0.9838 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 162/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0705 - acc: 0.9838 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 163/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0674 - acc: 0.9886 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 164/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0689 - acc: 0.9831 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 165/250\n",
      "2904/2904 [==============================] - 0s 19us/step - loss: 0.0708 - acc: 0.9835 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 166/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0678 - acc: 0.9862 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 167/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0651 - acc: 0.9873 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 168/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0657 - acc: 0.9866 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 169/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0626 - acc: 0.9886 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 170/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0619 - acc: 0.9893 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 171/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0627 - acc: 0.9893 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 172/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0645 - acc: 0.9855 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 173/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0668 - acc: 0.9886 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 174/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0647 - acc: 0.9862 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 175/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0674 - acc: 0.9886 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 176/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0626 - acc: 0.9862 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 177/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0574 - acc: 0.9904 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 178/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0564 - acc: 0.9897 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 179/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0538 - acc: 0.9931 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 180/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0561 - acc: 0.9893 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 181/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0590 - acc: 0.9869 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 182/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0553 - acc: 0.9900 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 183/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0551 - acc: 0.9900 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 184/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0518 - acc: 0.9938 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 185/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0519 - acc: 0.9893 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 186/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0539 - acc: 0.9921 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 187/250\n",
      "2904/2904 [==============================] - 0s 19us/step - loss: 0.0499 - acc: 0.9931 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 188/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0495 - acc: 0.9928 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 189/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0473 - acc: 0.9924 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 190/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0467 - acc: 0.9935 - val_loss: 8.0991 - val_acc: 0.4746\n",
      "Epoch 191/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0492 - acc: 0.9935 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 192/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0471 - acc: 0.9931 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 193/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0448 - acc: 0.9941 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 194/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0465 - acc: 0.9935 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 195/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0486 - acc: 0.9931 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 196/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0539 - acc: 0.9873 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 197/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0495 - acc: 0.9917 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 198/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0440 - acc: 0.9935 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 199/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0418 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 200/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0432 - acc: 0.9938 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 201/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0403 - acc: 0.9945 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 202/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0422 - acc: 0.9945 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 203/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0402 - acc: 0.9955 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 204/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0387 - acc: 0.9969 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 205/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9959 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 206/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0389 - acc: 0.9941 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 207/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0374 - acc: 0.9969 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 208/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0379 - acc: 0.9955 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 209/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0380 - acc: 0.9966 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 210/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0380 - acc: 0.9959 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 211/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0363 - acc: 0.9966 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 212/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0370 - acc: 0.9959 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 213/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0355 - acc: 0.9969 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 214/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0347 - acc: 0.9966 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 215/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0335 - acc: 0.9969 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 216/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0336 - acc: 0.9976 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 217/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0352 - acc: 0.9955 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 218/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0349 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 219/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0352 - acc: 0.9969 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 220/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0339 - acc: 0.9955 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 221/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0324 - acc: 0.9969 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 222/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0349 - acc: 0.9952 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 223/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0317 - acc: 0.9979 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 224/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0315 - acc: 0.9983 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 225/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0302 - acc: 0.9983 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 226/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0292 - acc: 0.9979 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 227/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0303 - acc: 0.9979 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 228/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0292 - acc: 0.9986 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 229/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0290 - acc: 0.9979 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 230/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0276 - acc: 0.9986 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 231/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0294 - acc: 0.9976 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 232/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0290 - acc: 0.9983 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 233/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0275 - acc: 0.9986 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 234/250\n",
      "2904/2904 [==============================] - 0s 20us/step - loss: 0.0280 - acc: 0.9972 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 235/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0263 - acc: 0.9990 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 236/250\n",
      "2904/2904 [==============================] - 0s 21us/step - loss: 0.0263 - acc: 0.9986 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 237/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0247 - acc: 0.9986 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 238/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0254 - acc: 0.9983 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 239/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0251 - acc: 0.9993 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 240/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0241 - acc: 0.9997 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 241/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0246 - acc: 0.9983 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 242/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0265 - acc: 0.9979 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 243/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0250 - acc: 0.9986 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 244/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0245 - acc: 0.9990 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 245/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0235 - acc: 0.9997 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 246/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0236 - acc: 0.9983 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 247/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0233 - acc: 0.9986 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 248/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0223 - acc: 0.9993 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 249/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0209 - acc: 0.9990 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 250/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0234 - acc: 0.9997 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "1452/1452 [==============================] - 0s 14us/step\n",
      "2904/2904 [==============================] - 0s 12us/step\n",
      "Train on 2904 samples, validate on 1867 samples\n",
      "Epoch 1/250\n",
      "2904/2904 [==============================] - 0s 157us/step - loss: 0.5445 - acc: 0.7748 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 2/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4943 - acc: 0.8010 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 3/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4786 - acc: 0.8051 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 4/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4702 - acc: 0.8079 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 5/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.4635 - acc: 0.8079 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 6/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.4590 - acc: 0.8106 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 7/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.4536 - acc: 0.8120 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 8/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4491 - acc: 0.8168 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 9/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4432 - acc: 0.8134 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 10/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4371 - acc: 0.8154 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 11/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4373 - acc: 0.8140 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 12/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4305 - acc: 0.8161 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 13/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4235 - acc: 0.8171 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 14/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4202 - acc: 0.8175 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 15/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4165 - acc: 0.8209 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 16/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.4121 - acc: 0.8206 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 17/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4141 - acc: 0.8237 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 18/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4056 - acc: 0.8261 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 19/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.4003 - acc: 0.8237 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 20/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3976 - acc: 0.8282 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 21/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3915 - acc: 0.8292 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 22/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.3913 - acc: 0.8326 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 23/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.3856 - acc: 0.8275 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 24/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.3812 - acc: 0.8337 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 25/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.3779 - acc: 0.8368 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 26/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.3734 - acc: 0.8395 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 27/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.3697 - acc: 0.8402 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 28/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3674 - acc: 0.8444 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 29/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3653 - acc: 0.8461 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 30/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.3594 - acc: 0.8495 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 31/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3558 - acc: 0.8495 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 32/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3530 - acc: 0.8492 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 33/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3492 - acc: 0.8502 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 34/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3477 - acc: 0.8561 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 35/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3438 - acc: 0.8564 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 36/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3382 - acc: 0.8571 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 37/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3363 - acc: 0.8581 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 38/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3334 - acc: 0.8678 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 39/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3300 - acc: 0.8633 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 40/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3242 - acc: 0.8671 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 41/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3217 - acc: 0.8685 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 42/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3173 - acc: 0.8719 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 43/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3158 - acc: 0.8743 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 44/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.3129 - acc: 0.8719 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 45/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3086 - acc: 0.8791 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 46/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3045 - acc: 0.8788 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 47/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2997 - acc: 0.8846 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 48/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2983 - acc: 0.8805 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 49/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2954 - acc: 0.8857 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 50/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.3000 - acc: 0.8836 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 51/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.2880 - acc: 0.8943 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 52/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2921 - acc: 0.8819 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 53/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2826 - acc: 0.8960 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 54/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2797 - acc: 0.8943 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 55/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2773 - acc: 0.8929 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 56/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2815 - acc: 0.8826 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 57/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2738 - acc: 0.8977 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 58/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2670 - acc: 0.9005 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 59/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2622 - acc: 0.9029 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 60/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2569 - acc: 0.9050 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 61/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2598 - acc: 0.9039 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 62/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2552 - acc: 0.9063 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 63/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2549 - acc: 0.9081 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 64/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2492 - acc: 0.9101 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 65/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2445 - acc: 0.9118 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 66/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2428 - acc: 0.9146 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 67/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2404 - acc: 0.9122 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 68/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2344 - acc: 0.9184 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 69/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2347 - acc: 0.9149 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 70/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2400 - acc: 0.9105 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 71/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2308 - acc: 0.9136 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 72/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2271 - acc: 0.9156 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 73/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2228 - acc: 0.9218 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 74/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2200 - acc: 0.9174 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 75/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2176 - acc: 0.9242 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 76/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.2138 - acc: 0.9301 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 77/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.2117 - acc: 0.9280 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 78/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2105 - acc: 0.9260 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 79/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2031 - acc: 0.9308 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 80/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.2015 - acc: 0.9329 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 81/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1979 - acc: 0.9332 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 82/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.2004 - acc: 0.9356 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 83/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1971 - acc: 0.9325 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 84/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1919 - acc: 0.9329 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 85/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1935 - acc: 0.9349 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 86/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1947 - acc: 0.9287 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 87/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1865 - acc: 0.9387 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 88/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1814 - acc: 0.9452 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 89/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1795 - acc: 0.9360 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 90/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1752 - acc: 0.9439 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 91/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1718 - acc: 0.9439 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 92/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1725 - acc: 0.9463 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 93/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1724 - acc: 0.9408 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 94/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1668 - acc: 0.9466 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 95/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1663 - acc: 0.9477 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 96/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1719 - acc: 0.9446 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 97/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1627 - acc: 0.9452 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 98/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1707 - acc: 0.9432 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 99/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1646 - acc: 0.9473 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 100/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1535 - acc: 0.9518 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 101/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1523 - acc: 0.9508 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 102/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1510 - acc: 0.9521 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 103/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1487 - acc: 0.9508 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 104/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1477 - acc: 0.9514 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 105/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1472 - acc: 0.9518 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 106/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1511 - acc: 0.9494 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 107/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1494 - acc: 0.9532 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 108/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1513 - acc: 0.9532 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 109/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1412 - acc: 0.9501 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 110/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1366 - acc: 0.9556 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 111/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1338 - acc: 0.9611 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 112/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1321 - acc: 0.9594 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 113/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1342 - acc: 0.9570 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 114/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1290 - acc: 0.9580 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 115/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1286 - acc: 0.9614 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 116/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1241 - acc: 0.9638 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 117/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.1253 - acc: 0.9638 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 118/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1277 - acc: 0.9566 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 119/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1288 - acc: 0.9580 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 120/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1230 - acc: 0.9621 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 121/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1220 - acc: 0.9628 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 122/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1198 - acc: 0.9659 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 123/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1167 - acc: 0.9683 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 124/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1127 - acc: 0.9687 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 125/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1089 - acc: 0.9704 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 126/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1112 - acc: 0.9694 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 127/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1104 - acc: 0.9683 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 128/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1106 - acc: 0.9659 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 129/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1089 - acc: 0.9697 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 130/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1132 - acc: 0.9649 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 131/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.1069 - acc: 0.9697 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 132/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1011 - acc: 0.9725 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 133/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0998 - acc: 0.9738 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 134/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.1003 - acc: 0.9749 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 135/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0995 - acc: 0.9742 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 136/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.1000 - acc: 0.9725 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 137/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0966 - acc: 0.9731 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 138/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0956 - acc: 0.9742 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 139/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0911 - acc: 0.9780 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 140/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0917 - acc: 0.9776 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 141/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0917 - acc: 0.9797 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 142/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0913 - acc: 0.9787 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 143/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0897 - acc: 0.9780 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 144/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0922 - acc: 0.9749 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 145/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0903 - acc: 0.9745 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 146/250\n",
      "2904/2904 [==============================] - 0s 10us/step - loss: 0.0873 - acc: 0.9783 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 147/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0884 - acc: 0.9790 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 148/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0835 - acc: 0.9783 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 149/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0808 - acc: 0.9814 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 150/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0798 - acc: 0.9811 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 151/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0792 - acc: 0.9824 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 152/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0771 - acc: 0.9838 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 153/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0768 - acc: 0.9838 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 154/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0747 - acc: 0.9835 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 155/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0748 - acc: 0.9828 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 156/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0755 - acc: 0.9828 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 157/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0752 - acc: 0.9814 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 158/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0737 - acc: 0.9842 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 159/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0746 - acc: 0.9811 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 160/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0750 - acc: 0.9814 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 161/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0709 - acc: 0.9848 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 162/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0671 - acc: 0.9873 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 163/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0656 - acc: 0.9890 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 164/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0669 - acc: 0.9869 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 165/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0653 - acc: 0.9876 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 166/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0660 - acc: 0.9890 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 167/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0638 - acc: 0.9873 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 168/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0613 - acc: 0.9893 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 169/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0642 - acc: 0.9848 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 170/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0639 - acc: 0.9883 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 171/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0632 - acc: 0.9855 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 172/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0617 - acc: 0.9886 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 173/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0598 - acc: 0.9876 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 174/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0583 - acc: 0.9897 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 175/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0554 - acc: 0.9921 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 176/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0582 - acc: 0.9893 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 177/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0625 - acc: 0.9848 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 178/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0593 - acc: 0.9879 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 179/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0597 - acc: 0.9883 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 180/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0559 - acc: 0.9890 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 181/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0531 - acc: 0.9910 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 182/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0534 - acc: 0.9900 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 183/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0554 - acc: 0.9893 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 184/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0538 - acc: 0.9914 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 185/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0559 - acc: 0.9879 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 186/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0490 - acc: 0.9935 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 187/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0504 - acc: 0.9931 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 188/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0489 - acc: 0.9928 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 189/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0471 - acc: 0.9935 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 190/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0463 - acc: 0.9941 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 191/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0463 - acc: 0.9941 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 192/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0451 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 193/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0442 - acc: 0.9935 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 194/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0470 - acc: 0.9941 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 195/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0481 - acc: 0.9931 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 196/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0484 - acc: 0.9907 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 197/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0471 - acc: 0.9914 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 198/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0447 - acc: 0.9935 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 199/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0493 - acc: 0.9921 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 200/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0455 - acc: 0.9924 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 201/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0417 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 202/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0402 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 203/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0431 - acc: 0.9931 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 204/250\n",
      "2904/2904 [==============================] - 0s 12us/step - loss: 0.0419 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 205/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0402 - acc: 0.9948 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 206/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0389 - acc: 0.9955 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 207/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0397 - acc: 0.9948 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 208/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0400 - acc: 0.9948 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 209/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0368 - acc: 0.9955 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 210/250\n",
      "2904/2904 [==============================] - 0s 17us/step - loss: 0.0363 - acc: 0.9969 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 211/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0364 - acc: 0.9962 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 212/250\n",
      "2904/2904 [==============================] - 0s 18us/step - loss: 0.0391 - acc: 0.9928 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 213/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0366 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 214/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0340 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 215/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0337 - acc: 0.9966 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 216/250\n",
      "2904/2904 [==============================] - 0s 20us/step - loss: 0.0343 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 217/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0323 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 218/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0340 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 219/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0327 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 220/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0332 - acc: 0.9966 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 221/250\n",
      "2904/2904 [==============================] - 0s 22us/step - loss: 0.0331 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 222/250\n",
      "2904/2904 [==============================] - 0s 20us/step - loss: 0.0359 - acc: 0.9945 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 223/250\n",
      "2904/2904 [==============================] - 0s 19us/step - loss: 0.0315 - acc: 0.9983 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 224/250\n",
      "2904/2904 [==============================] - 0s 20us/step - loss: 0.0310 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 225/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0324 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 226/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0313 - acc: 0.9962 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 227/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0305 - acc: 0.9969 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 228/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0330 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 229/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0311 - acc: 0.9966 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 230/250\n",
      "2904/2904 [==============================] - 0s 11us/step - loss: 0.0310 - acc: 0.9969 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 231/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0295 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 232/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0278 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 233/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0281 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 234/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0266 - acc: 0.9983 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 235/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0254 - acc: 0.9983 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 236/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0276 - acc: 0.9969 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 237/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0279 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 238/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0283 - acc: 0.9966 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 239/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0279 - acc: 0.9962 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 240/250\n",
      "2904/2904 [==============================] - 0s 16us/step - loss: 0.0265 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 241/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0251 - acc: 0.9979 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 242/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0244 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 243/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0253 - acc: 0.9986 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 244/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0248 - acc: 0.9976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 245/250\n",
      "2904/2904 [==============================] - 0s 15us/step - loss: 0.0233 - acc: 0.9986 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 246/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0230 - acc: 0.9990 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 247/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0228 - acc: 0.9986 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 248/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0224 - acc: 0.9983 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 249/250\n",
      "2904/2904 [==============================] - 0s 13us/step - loss: 0.0218 - acc: 0.9986 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 250/250\n",
      "2904/2904 [==============================] - 0s 14us/step - loss: 0.0219 - acc: 0.9983 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "1452/1452 [==============================] - 0s 16us/step\n",
      "2904/2904 [==============================] - 0s 15us/step\n",
      "Train on 4356 samples, validate on 1867 samples\n",
      "Epoch 1/250\n",
      "4356/4356 [==============================] - 0s 102us/step - loss: 0.5304 - acc: 0.7780 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 2/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4877 - acc: 0.7994 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 3/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.4767 - acc: 0.8021 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 4/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.4709 - acc: 0.8035 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 5/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.4635 - acc: 0.8081 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 6/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4578 - acc: 0.8069 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 7/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4545 - acc: 0.8081 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 8/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.4519 - acc: 0.8069 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 9/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.4497 - acc: 0.8039 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 10/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.4417 - acc: 0.8136 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 11/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4367 - acc: 0.8127 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 12/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4334 - acc: 0.8138 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 13/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4278 - acc: 0.8173 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 14/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4248 - acc: 0.8173 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 15/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.4216 - acc: 0.8182 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 16/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4188 - acc: 0.8177 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 17/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.4156 - acc: 0.8184 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 18/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4107 - acc: 0.8214 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 19/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4088 - acc: 0.8196 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 20/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.4068 - acc: 0.8216 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 21/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.4012 - acc: 0.8244 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 22/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3986 - acc: 0.8260 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 23/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3936 - acc: 0.8264 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 24/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3912 - acc: 0.8303 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 25/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3877 - acc: 0.8313 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 26/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3843 - acc: 0.8315 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 27/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3811 - acc: 0.8347 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 28/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3762 - acc: 0.8382 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 29/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3746 - acc: 0.8347 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 30/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3749 - acc: 0.8425 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 31/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3689 - acc: 0.8430 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 32/250\n",
      "4356/4356 [==============================] - 0s 10us/step - loss: 0.3656 - acc: 0.8432 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 33/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3642 - acc: 0.8441 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 34/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3584 - acc: 0.8492 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 35/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3547 - acc: 0.8469 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 36/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3544 - acc: 0.8489 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 37/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3501 - acc: 0.8501 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 38/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3492 - acc: 0.8551 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 39/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3421 - acc: 0.8579 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 40/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3417 - acc: 0.8588 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 41/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3348 - acc: 0.8636 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 42/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3355 - acc: 0.8611 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 43/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3296 - acc: 0.8602 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 44/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3249 - acc: 0.8696 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 45/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3255 - acc: 0.8671 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 46/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.3230 - acc: 0.8613 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 47/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3183 - acc: 0.8701 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 48/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3149 - acc: 0.8728 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 49/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.3106 - acc: 0.8730 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 50/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3058 - acc: 0.8779 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 51/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3057 - acc: 0.8765 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 52/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3013 - acc: 0.8797 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 53/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.3032 - acc: 0.8783 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 54/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2987 - acc: 0.8751 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 55/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2946 - acc: 0.8809 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 56/250\n",
      "4356/4356 [==============================] - 0s 10us/step - loss: 0.2902 - acc: 0.8907 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 57/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2842 - acc: 0.8914 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 58/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2830 - acc: 0.8907 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 59/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2795 - acc: 0.8946 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 60/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2760 - acc: 0.8937 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 61/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2757 - acc: 0.8967 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 62/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2698 - acc: 0.9011 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 63/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2686 - acc: 0.8972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 64/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2738 - acc: 0.8967 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 65/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2726 - acc: 0.8976 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 66/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2655 - acc: 0.8981 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 67/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.2603 - acc: 0.9068 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 68/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.2544 - acc: 0.9061 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 69/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.2543 - acc: 0.9075 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 70/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2534 - acc: 0.9034 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 71/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.2492 - acc: 0.9093 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 72/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2467 - acc: 0.9093 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 73/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2505 - acc: 0.9070 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 74/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.2442 - acc: 0.9125 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 75/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2393 - acc: 0.9098 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 76/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.2365 - acc: 0.9125 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 77/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.2386 - acc: 0.9086 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 78/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2319 - acc: 0.9160 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 79/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2392 - acc: 0.9082 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 80/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.2323 - acc: 0.9121 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 81/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2378 - acc: 0.9105 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 82/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2273 - acc: 0.9155 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 83/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2229 - acc: 0.9197 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 84/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2190 - acc: 0.9206 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 85/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2174 - acc: 0.9238 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 86/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2134 - acc: 0.9258 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 87/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.2108 - acc: 0.9272 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 88/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.2099 - acc: 0.9277 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 89/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2053 - acc: 0.9309 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 90/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2077 - acc: 0.9268 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 91/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2046 - acc: 0.9288 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 92/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2000 - acc: 0.9304 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 93/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.2014 - acc: 0.9298 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 94/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.2023 - acc: 0.9270 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 95/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1964 - acc: 0.9300 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 96/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1979 - acc: 0.9318 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 97/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1956 - acc: 0.9318 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 98/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1876 - acc: 0.9355 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 99/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1882 - acc: 0.9341 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 100/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1873 - acc: 0.9357 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 101/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1888 - acc: 0.9346 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 102/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1815 - acc: 0.9378 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 103/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1791 - acc: 0.9415 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 104/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1762 - acc: 0.9449 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 105/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1740 - acc: 0.9433 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 106/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1730 - acc: 0.9426 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 107/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1717 - acc: 0.9415 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 108/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1667 - acc: 0.9444 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 109/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1671 - acc: 0.9444 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 110/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1656 - acc: 0.9451 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 111/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1703 - acc: 0.9438 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 112/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1683 - acc: 0.9410 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 113/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1734 - acc: 0.9355 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 114/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1612 - acc: 0.9502 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 115/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1617 - acc: 0.9472 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 116/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1628 - acc: 0.9502 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 117/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1562 - acc: 0.9479 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 118/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1520 - acc: 0.9529 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 119/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1505 - acc: 0.9534 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 120/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1478 - acc: 0.9550 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 121/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1437 - acc: 0.9562 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 122/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1427 - acc: 0.9564 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 123/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1473 - acc: 0.9539 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 124/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1397 - acc: 0.9578 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 125/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1386 - acc: 0.9559 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 126/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1391 - acc: 0.9578 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 127/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1356 - acc: 0.9573 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 128/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1394 - acc: 0.9555 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 129/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1408 - acc: 0.9575 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 130/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1310 - acc: 0.9596 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 131/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1315 - acc: 0.9624 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 132/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1303 - acc: 0.9628 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 133/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1274 - acc: 0.9619 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 134/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1307 - acc: 0.9637 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 135/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1327 - acc: 0.9591 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 136/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1263 - acc: 0.9605 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 137/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1249 - acc: 0.9624 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 138/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.1215 - acc: 0.9628 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 139/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1219 - acc: 0.9640 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 140/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1216 - acc: 0.9646 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 141/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1175 - acc: 0.9663 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 142/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1138 - acc: 0.9674 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 143/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1126 - acc: 0.9676 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 144/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1115 - acc: 0.9692 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 145/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1115 - acc: 0.9665 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 146/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1140 - acc: 0.9679 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 147/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.1148 - acc: 0.9646 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 148/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1123 - acc: 0.9667 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 149/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1099 - acc: 0.9697 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 150/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.1104 - acc: 0.9679 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 151/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.1121 - acc: 0.9683 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 152/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.1052 - acc: 0.9720 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 153/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.1018 - acc: 0.9725 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 154/250\n",
      "4356/4356 [==============================] - 0s 17us/step - loss: 0.1055 - acc: 0.9699 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 155/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.1066 - acc: 0.9685 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 156/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.1002 - acc: 0.9718 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 157/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0975 - acc: 0.9731 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 158/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0963 - acc: 0.9752 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 159/250\n",
      "4356/4356 [==============================] - 0s 17us/step - loss: 0.0985 - acc: 0.9745 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 160/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0979 - acc: 0.9745 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 161/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0975 - acc: 0.9738 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 162/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0967 - acc: 0.9775 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 163/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0929 - acc: 0.9754 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 164/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0918 - acc: 0.9775 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 165/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0913 - acc: 0.9754 - val_loss: 3.9281 - val_acc: 0.7563\n",
      "Epoch 166/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0908 - acc: 0.9775 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 167/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.0907 - acc: 0.9784 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 168/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0862 - acc: 0.9793 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 169/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.0855 - acc: 0.9787 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 170/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0832 - acc: 0.9803 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 171/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0847 - acc: 0.9789 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 172/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0915 - acc: 0.9773 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 173/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0822 - acc: 0.9805 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 174/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0841 - acc: 0.9787 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 175/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0800 - acc: 0.9816 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 176/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0789 - acc: 0.9807 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 177/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0864 - acc: 0.9745 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 178/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0783 - acc: 0.9814 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 179/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0751 - acc: 0.9844 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 180/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0746 - acc: 0.9851 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 181/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0758 - acc: 0.9837 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 182/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0802 - acc: 0.9770 - val_loss: 3.9282 - val_acc: 0.7563\n",
      "Epoch 183/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0765 - acc: 0.9814 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 184/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0783 - acc: 0.9812 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 185/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0740 - acc: 0.9839 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 186/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0709 - acc: 0.9842 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 187/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0705 - acc: 0.9830 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 188/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0691 - acc: 0.9855 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 189/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0677 - acc: 0.9858 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 190/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0687 - acc: 0.9858 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 191/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0683 - acc: 0.9862 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 192/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0659 - acc: 0.9860 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 193/250\n",
      "4356/4356 [==============================] - 0s 22us/step - loss: 0.0651 - acc: 0.9869 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 194/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.0692 - acc: 0.9821 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 195/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.0658 - acc: 0.9846 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 196/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0605 - acc: 0.9876 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 197/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.0604 - acc: 0.9888 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 198/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.0646 - acc: 0.9846 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 199/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0617 - acc: 0.9883 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 200/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0599 - acc: 0.9885 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 201/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0593 - acc: 0.9883 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 202/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.0608 - acc: 0.9885 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 203/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.0599 - acc: 0.9883 - val_loss: 9.3330 - val_acc: 0.4087\n",
      "Epoch 204/250\n",
      "4356/4356 [==============================] - 0s 11us/step - loss: 0.0569 - acc: 0.9901 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 205/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0584 - acc: 0.9885 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 206/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0598 - acc: 0.9883 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 207/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0631 - acc: 0.9862 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 208/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.0649 - acc: 0.9842 - val_loss: 3.9809 - val_acc: 0.7525\n",
      "Epoch 209/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0615 - acc: 0.9876 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 210/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0589 - acc: 0.9869 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 211/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0549 - acc: 0.9890 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 212/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0519 - acc: 0.9894 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 213/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0571 - acc: 0.9878 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 214/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.0520 - acc: 0.9890 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 215/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0489 - acc: 0.9922 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 216/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0548 - acc: 0.9869 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 217/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0496 - acc: 0.9929 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 218/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0494 - acc: 0.9915 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 219/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0539 - acc: 0.9899 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 220/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.0508 - acc: 0.9910 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 221/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0492 - acc: 0.9894 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 222/250\n",
      "4356/4356 [==============================] - 0s 18us/step - loss: 0.0481 - acc: 0.9899 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 223/250\n",
      "4356/4356 [==============================] - 0s 19us/step - loss: 0.0512 - acc: 0.9888 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 224/250\n",
      "4356/4356 [==============================] - 0s 19us/step - loss: 0.0453 - acc: 0.9943 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 225/250\n",
      "4356/4356 [==============================] - 0s 21us/step - loss: 0.0482 - acc: 0.9915 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 226/250\n",
      "4356/4356 [==============================] - 0s 18us/step - loss: 0.0495 - acc: 0.9910 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 227/250\n",
      "4356/4356 [==============================] - 0s 18us/step - loss: 0.0429 - acc: 0.9954 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 228/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0422 - acc: 0.9943 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 229/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.0443 - acc: 0.9922 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 230/250\n",
      "4356/4356 [==============================] - 0s 18us/step - loss: 0.0442 - acc: 0.9938 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 231/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0443 - acc: 0.9922 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 232/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0437 - acc: 0.9927 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 233/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0421 - acc: 0.9936 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 234/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0392 - acc: 0.9947 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 235/250\n",
      "4356/4356 [==============================] - 0s 17us/step - loss: 0.0389 - acc: 0.9947 - val_loss: 3.9281 - val_acc: 0.7563\n",
      "Epoch 236/250\n",
      "4356/4356 [==============================] - 0s 17us/step - loss: 0.0383 - acc: 0.9943 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 237/250\n",
      "4356/4356 [==============================] - 0s 16us/step - loss: 0.0370 - acc: 0.9956 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 238/250\n",
      "4356/4356 [==============================] - 0s 15us/step - loss: 0.0376 - acc: 0.9975 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 239/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0372 - acc: 0.9959 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 240/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0398 - acc: 0.9933 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 241/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0376 - acc: 0.9954 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 242/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0380 - acc: 0.9940 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 243/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0367 - acc: 0.9959 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 244/250\n",
      "4356/4356 [==============================] - 0s 14us/step - loss: 0.0407 - acc: 0.9931 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 245/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0394 - acc: 0.9936 - val_loss: 3.9195 - val_acc: 0.7568\n",
      "Epoch 246/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0369 - acc: 0.9952 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 247/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0349 - acc: 0.9963 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 248/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0341 - acc: 0.9961 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 249/250\n",
      "4356/4356 [==============================] - 0s 13us/step - loss: 0.0327 - acc: 0.9972 - val_loss: 12.1986 - val_acc: 0.2432\n",
      "Epoch 250/250\n",
      "4356/4356 [==============================] - 0s 12us/step - loss: 0.0336 - acc: 0.9966 - val_loss: 3.9195 - val_acc: 0.7568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x11d150748>,\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'dense_layer_sizes': [[120, 120]], 'epochs': [250], 'activation': ['relu'], 'optimizer': ['adam']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_size_candidates = [[120, 120]]\n",
    "classifier = KerasClassifier(make_model)\n",
    "validator = GridSearchCV(classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     'epochs': [250],\n",
    "                                     'activation': ['relu'],\n",
    "                                     'optimizer': ['adam'],\n",
    "                                    }, n_jobs=1)\n",
    "validator.fit(X_train_scaled, y_train_categorical, validation_data=(X_val, y_val_categorical), batch_size=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters of the best model are: \n",
      "{'activation': 'relu', 'dense_layer_sizes': [120, 120], 'epochs': 250, 'optimizer': 'adam'}\n",
      "0.7573461890549043\n"
     ]
    }
   ],
   "source": [
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)\n",
    "print(validator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2668/2668 [==============================] - 0s 19us/step\n",
      "loss :  1.1657796883690303\n",
      "acc :  0.7631184408689725\n"
     ]
    }
   ],
   "source": [
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(X_test_scaled, y_test_categorical)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join('..', 'model', 'grammy_prediction_model.h5')\n",
    "best_model.save(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Acousticness', 'Danceability', 'Duration (ms)', 'Energy',\n",
       "       'Instrumentalness', 'Liveness', 'Loudness', 'Mode', 'Speechiness',\n",
       "       'Tempo', 'Time Signature', 'Valence', 'Explicit', 'Popularity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/grammy_prediction_scaler.sav']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "scaler_file = os.path.join('..', 'model', 'grammy_prediction_scaler.sav')\n",
    "joblib.dump(X_scaler, scaler_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = validator.best_estimator_.model.history\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
