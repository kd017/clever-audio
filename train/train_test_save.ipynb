{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMBINED_DATA = os.path.join('..', 'data', 'combined-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>TrackId</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Album</th>\n",
       "      <th>Image</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958</td>\n",
       "      <td>Nel Blu Dipinto Di Blu (Volare)</td>\n",
       "      <td>Nel Blu Dipinto Di Blu (Volare)</td>\n",
       "      <td>https://open.spotify.com/track/006Ndmw2hHxvnLb...</td>\n",
       "      <td>006Ndmw2hHxvnLbJsBFnPx</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>Tutto Modugno (Mister Volare)</td>\n",
       "      <td>https://i.scdn.co/image/5e8c49f7a8d161c1d65109...</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1958</td>\n",
       "      <td>Henry Mancini</td>\n",
       "      <td>The Music From Peter Gunn</td>\n",
       "      <td>https://open.spotify.com/track/3BdPP6Xce6FUcfa...</td>\n",
       "      <td>3BdPP6Xce6FUcfaCFsnZIg</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.550</td>\n",
       "      <td>177733.0</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>138.037</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>The music from Peter Gunn</td>\n",
       "      <td>https://i.scdn.co/image/1ad2e8ce1f988c27678298...</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1958</td>\n",
       "      <td>Ella Fitzgerald</td>\n",
       "      <td>Ella Fitzgerald Sings The Irving Berlin Song Book</td>\n",
       "      <td>https://open.spotify.com/track/5FY0EikZVSBOwpj...</td>\n",
       "      <td>5FY0EikZVSBOwpjQa9S5Ii</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.615</td>\n",
       "      <td>138320.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>73.007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>Ella Fitzgerald Sings The Irving Berlin Song Book</td>\n",
       "      <td>https://i.scdn.co/image/3350581fb4712a44a6f6b5...</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>Catch A Falling Star</td>\n",
       "      <td>Catch A Falling Star</td>\n",
       "      <td>https://open.spotify.com/track/0qu9P0DcFcgAycR...</td>\n",
       "      <td>0qu9P0DcFcgAycRsbWupnZ</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.726</td>\n",
       "      <td>176840.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>109.158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.712</td>\n",
       "      <td>I Just Came Home To Count The Memories</td>\n",
       "      <td>https://i.scdn.co/image/848ede6cee3d8111533c7e...</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>Billy May's Big Fat Brass</td>\n",
       "      <td>Billy May's Big Fat Brass</td>\n",
       "      <td>https://open.spotify.com/track/4fv9FQ1TNeAYw8z...</td>\n",
       "      <td>4fv9FQ1TNeAYw8zJrVMUi7</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.711</td>\n",
       "      <td>145907.0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>115.418</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.552</td>\n",
       "      <td>Billy May's Big Fat Brass</td>\n",
       "      <td>https://i.scdn.co/image/04fbb97c5d46c80d9fc9e1...</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                           Artist  \\\n",
       "0  1958  Nel Blu Dipinto Di Blu (Volare)   \n",
       "1  1958                    Henry Mancini   \n",
       "2  1958                  Ella Fitzgerald   \n",
       "3  1958             Catch A Falling Star   \n",
       "4  1958        Billy May's Big Fat Brass   \n",
       "\n",
       "                                               Title  \\\n",
       "0                    Nel Blu Dipinto Di Blu (Volare)   \n",
       "1                          The Music From Peter Gunn   \n",
       "2  Ella Fitzgerald Sings The Irving Berlin Song Book   \n",
       "3                               Catch A Falling Star   \n",
       "4                          Billy May's Big Fat Brass   \n",
       "\n",
       "                                                 URL                 TrackId  \\\n",
       "0  https://open.spotify.com/track/006Ndmw2hHxvnLb...  006Ndmw2hHxvnLbJsBFnPx   \n",
       "1  https://open.spotify.com/track/3BdPP6Xce6FUcfa...  3BdPP6Xce6FUcfaCFsnZIg   \n",
       "2  https://open.spotify.com/track/5FY0EikZVSBOwpj...  5FY0EikZVSBOwpjQa9S5Ii   \n",
       "3  https://open.spotify.com/track/0qu9P0DcFcgAycR...  0qu9P0DcFcgAycRsbWupnZ   \n",
       "4  https://open.spotify.com/track/4fv9FQ1TNeAYw8z...  4fv9FQ1TNeAYw8zJrVMUi7   \n",
       "\n",
       "   Acousticness  Danceability  Duration (ms)  Energy  Instrumentalness  ...    \\\n",
       "0         0.987         0.518       216373.0   0.060          0.000008  ...     \n",
       "1         0.893         0.550       177733.0   0.318          0.881000  ...     \n",
       "2         0.675         0.615       138320.0   0.186          0.000000  ...     \n",
       "3         0.259         0.726       176840.0   0.330          0.000309  ...     \n",
       "4         0.421         0.711       145907.0   0.254          0.000045  ...     \n",
       "\n",
       "   Mode  Speechiness    Tempo  Time Signature  Valence  \\\n",
       "0   1.0       0.0441  127.870             4.0    0.336   \n",
       "1   1.0       0.0313  138.037             4.0    0.620   \n",
       "2   0.0       0.0508   73.007             4.0    0.749   \n",
       "3   1.0       0.0330  109.158             4.0    0.712   \n",
       "4   0.0       0.0374  115.418             4.0    0.552   \n",
       "\n",
       "                                               Album  \\\n",
       "0                      Tutto Modugno (Mister Volare)   \n",
       "1                          The music from Peter Gunn   \n",
       "2  Ella Fitzgerald Sings The Irving Berlin Song Book   \n",
       "3             I Just Came Home To Count The Memories   \n",
       "4                          Billy May's Big Fat Brass   \n",
       "\n",
       "                                               Image  Explicit Popularity  \\\n",
       "0  https://i.scdn.co/image/5e8c49f7a8d161c1d65109...     False       35.0   \n",
       "1  https://i.scdn.co/image/1ad2e8ce1f988c27678298...     False       16.0   \n",
       "2  https://i.scdn.co/image/3350581fb4712a44a6f6b5...     False       34.0   \n",
       "3  https://i.scdn.co/image/848ede6cee3d8111533c7e...     False       39.0   \n",
       "4  https://i.scdn.co/image/04fbb97c5d46c80d9fc9e1...     False        9.0   \n",
       "\n",
       "  Winner  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df = pd.read_csv(COMBINED_DATA)\n",
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Artist', 'Title', 'URL', 'TrackId', 'Acousticness',\n",
       "       'Danceability', 'Duration (ms)', 'Energy', 'Instrumentalness', 'Key',\n",
       "       'Liveness', 'Loudness', 'Mode', 'Speechiness', 'Tempo',\n",
       "       'Time Signature', 'Valence', 'Album', 'Image', 'Explicit', 'Popularity',\n",
       "       'Winner'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Duration (ms)</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Key</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time Signature</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.518</td>\n",
       "      <td>216373.0</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>-14.887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>127.870</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>False</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.550</td>\n",
       "      <td>177733.0</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>-14.516</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>138.037</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.620</td>\n",
       "      <td>False</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.615</td>\n",
       "      <td>138320.0</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>-12.382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>73.007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.726</td>\n",
       "      <td>176840.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>-14.864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0330</td>\n",
       "      <td>109.158</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.712</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1958</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.711</td>\n",
       "      <td>145907.0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>-12.661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>115.418</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.552</td>\n",
       "      <td>False</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Acousticness  Danceability  Duration (ms)  Energy  Instrumentalness  \\\n",
       "0  1958         0.987         0.518       216373.0   0.060          0.000008   \n",
       "1  1958         0.893         0.550       177733.0   0.318          0.881000   \n",
       "2  1958         0.675         0.615       138320.0   0.186          0.000000   \n",
       "3  1958         0.259         0.726       176840.0   0.330          0.000309   \n",
       "4  1958         0.421         0.711       145907.0   0.254          0.000045   \n",
       "\n",
       "    Key  Liveness  Loudness  Mode  Speechiness    Tempo  Time Signature  \\\n",
       "0  10.0    0.1610   -14.887   1.0       0.0441  127.870             4.0   \n",
       "1   0.0    0.0311   -14.516   1.0       0.0313  138.037             4.0   \n",
       "2   0.0    0.1940   -12.382   0.0       0.0508   73.007             4.0   \n",
       "3   1.0    0.0704   -14.864   1.0       0.0330  109.158             4.0   \n",
       "4   0.0    0.1360   -12.661   0.0       0.0374  115.418             4.0   \n",
       "\n",
       "   Valence  Explicit  Popularity  \n",
       "0    0.336     False        35.0  \n",
       "1    0.620     False        16.0  \n",
       "2    0.749     False        34.0  \n",
       "3    0.712     False        39.0  \n",
       "4    0.552     False         9.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = songs_df.drop(labels=['Artist', 'Title', 'URL', 'TrackId', 'Album', 'Image', 'Winner'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                  int64\n",
       "Acousticness        float64\n",
       "Danceability        float64\n",
       "Duration (ms)       float64\n",
       "Energy              float64\n",
       "Instrumentalness    float64\n",
       "Key                 float64\n",
       "Liveness            float64\n",
       "Loudness            float64\n",
       "Mode                float64\n",
       "Speechiness         float64\n",
       "Tempo               float64\n",
       "Time Signature      float64\n",
       "Valence             float64\n",
       "Explicit               bool\n",
       "Popularity          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.Explicit = X.Explicit.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13379\n",
       "1     1107\n",
       "Name: Explicit, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.Explicit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluded_features = ['Year',  'Duration (ms)', 'Key',  'Mode', 'Speechiness', 'Tempo', 'Valence', 'Explicit']\n",
    "excluded_features = ['Popularity']\n",
    "X.drop(labels=excluded_features, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = songs_df['Winner']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10940\n",
       "1     3546\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, Normalizer, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, shuffle=True, stratify=y)\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Convert labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14486, 15)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dims = len(X.columns)\n",
    "# Create model and add layers\n",
    "def make_model(dense_layer_sizes, activation):\n",
    "    model = Sequential()\n",
    "    for dense_layer in dense_layer_sizes:\n",
    "        model.add(Dense(units=dense_layer, activation=activation, input_dim=dims))\n",
    "        \n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kishore/Tools/anaconda3/envs/PythonStuff/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7242 samples, validate on 3622 samples\n",
      "Epoch 1/115\n",
      "7242/7242 [==============================] - 1s 109us/step - loss: 0.4820 - acc: 0.7980 - val_loss: 3.9561 - val_acc: 0.7546\n",
      "Epoch 2/115\n",
      "7242/7242 [==============================] - 0s 59us/step - loss: 0.4583 - acc: 0.8046 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 3/115\n",
      "7242/7242 [==============================] - 0s 59us/step - loss: 0.4503 - acc: 0.8105 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 4/115\n",
      "7242/7242 [==============================] - 0s 48us/step - loss: 0.4420 - acc: 0.8128 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 5/115\n",
      "7242/7242 [==============================] - 0s 57us/step - loss: 0.4361 - acc: 0.8148 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 6/115\n",
      "7242/7242 [==============================] - 0s 52us/step - loss: 0.4309 - acc: 0.8168 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 7/115\n",
      "7242/7242 [==============================] - 0s 55us/step - loss: 0.4246 - acc: 0.8210 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 8/115\n",
      "7242/7242 [==============================] - 0s 51us/step - loss: 0.4194 - acc: 0.8237 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 9/115\n",
      "7242/7242 [==============================] - 0s 57us/step - loss: 0.4127 - acc: 0.8252 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 10/115\n",
      "7242/7242 [==============================] - 0s 51us/step - loss: 0.4069 - acc: 0.8310 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 11/115\n",
      "7242/7242 [==============================] - 0s 56us/step - loss: 0.4020 - acc: 0.8318 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 12/115\n",
      "7242/7242 [==============================] - 0s 56us/step - loss: 0.3954 - acc: 0.8315 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 13/115\n",
      "7242/7242 [==============================] - 0s 50us/step - loss: 0.3889 - acc: 0.8365 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 14/115\n",
      "7242/7242 [==============================] - 0s 53us/step - loss: 0.3854 - acc: 0.8387 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 15/115\n",
      "7242/7242 [==============================] - 0s 52us/step - loss: 0.3765 - acc: 0.8411 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 16/115\n",
      "7242/7242 [==============================] - 0s 53us/step - loss: 0.3728 - acc: 0.8452 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 17/115\n",
      "7242/7242 [==============================] - 0s 52us/step - loss: 0.3648 - acc: 0.8452 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 18/115\n",
      "7242/7242 [==============================] - 0s 54us/step - loss: 0.3589 - acc: 0.8494 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 19/115\n",
      "7242/7242 [==============================] - 0s 50us/step - loss: 0.3532 - acc: 0.8487 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 20/115\n",
      "7242/7242 [==============================] - 0s 56us/step - loss: 0.3490 - acc: 0.8517 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 21/115\n",
      "7242/7242 [==============================] - 0s 52us/step - loss: 0.3420 - acc: 0.8568 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 22/115\n",
      "7242/7242 [==============================] - 0s 54us/step - loss: 0.3340 - acc: 0.8589 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 23/115\n",
      "7242/7242 [==============================] - 0s 53us/step - loss: 0.3291 - acc: 0.8627 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 24/115\n",
      "7242/7242 [==============================] - 0s 54us/step - loss: 0.3253 - acc: 0.8643 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 25/115\n",
      "7242/7242 [==============================] - 0s 51us/step - loss: 0.3181 - acc: 0.8658 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 26/115\n",
      "7242/7242 [==============================] - 0s 57us/step - loss: 0.3113 - acc: 0.8724 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 27/115\n",
      "7242/7242 [==============================] - 0s 53us/step - loss: 0.3031 - acc: 0.8748 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 28/115\n",
      "7242/7242 [==============================] - 0s 51us/step - loss: 0.3027 - acc: 0.8766 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 29/115\n",
      "7242/7242 [==============================] - 0s 51us/step - loss: 0.2977 - acc: 0.8750 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 30/115\n",
      "7242/7242 [==============================] - 0s 54us/step - loss: 0.2888 - acc: 0.8812 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 31/115\n",
      "7242/7242 [==============================] - 0s 50us/step - loss: 0.2859 - acc: 0.8835 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 32/115\n",
      "7242/7242 [==============================] - 0s 50us/step - loss: 0.2757 - acc: 0.8872 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 33/115\n",
      "7242/7242 [==============================] - 0s 50us/step - loss: 0.2684 - acc: 0.8904 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 34/115\n",
      "7242/7242 [==============================] - 0s 55us/step - loss: 0.2657 - acc: 0.8919 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 35/115\n",
      "7242/7242 [==============================] - 0s 52us/step - loss: 0.2652 - acc: 0.8944 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 36/115\n",
      "7242/7242 [==============================] - 0s 51us/step - loss: 0.2566 - acc: 0.8941 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 37/115\n",
      "7242/7242 [==============================] - 1s 74us/step - loss: 0.2478 - acc: 0.8980 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 38/115\n",
      "7242/7242 [==============================] - 1s 71us/step - loss: 0.2418 - acc: 0.9050 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 39/115\n",
      "7242/7242 [==============================] - 0s 49us/step - loss: 0.2417 - acc: 0.8995 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 40/115\n",
      "7242/7242 [==============================] - 0s 47us/step - loss: 0.2321 - acc: 0.9082 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 41/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.2340 - acc: 0.9069 - val_loss: 3.9516 - val_acc: 0.7548\n",
      "Epoch 42/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.2244 - acc: 0.9127 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 43/115\n",
      "7242/7242 [==============================] - 0s 39us/step - loss: 0.2189 - acc: 0.9149 - val_loss: 3.9650 - val_acc: 0.7540\n",
      "Epoch 44/115\n",
      "7242/7242 [==============================] - 0s 39us/step - loss: 0.2102 - acc: 0.9181 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 45/115\n",
      "7242/7242 [==============================] - 0s 53us/step - loss: 0.2085 - acc: 0.9206 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 46/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.2035 - acc: 0.9220 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 47/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.2030 - acc: 0.9213 - val_loss: 3.9650 - val_acc: 0.7540\n",
      "Epoch 48/115\n",
      "7242/7242 [==============================] - 0s 41us/step - loss: 0.1969 - acc: 0.9247 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 49/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.1866 - acc: 0.9328 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 50/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.1824 - acc: 0.9307 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 51/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.1799 - acc: 0.9303 - val_loss: 3.9516 - val_acc: 0.7548\n",
      "Epoch 52/115\n",
      "7242/7242 [==============================] - 0s 41us/step - loss: 0.1758 - acc: 0.9318 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 53/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.1727 - acc: 0.9368 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 54/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.1721 - acc: 0.9343 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 55/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.1587 - acc: 0.9430 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 56/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.1622 - acc: 0.9373 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 57/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.1571 - acc: 0.9428 - val_loss: 4.0045 - val_acc: 0.7512\n",
      "Epoch 58/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.1489 - acc: 0.9456 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 59/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.1475 - acc: 0.9470 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 60/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.1480 - acc: 0.9471 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 61/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.1442 - acc: 0.9449 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 62/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.1374 - acc: 0.9515 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 63/115\n",
      "7242/7242 [==============================] - 0s 39us/step - loss: 0.1290 - acc: 0.9544 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 64/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.1262 - acc: 0.9558 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 65/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.1288 - acc: 0.9536 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 66/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.1249 - acc: 0.9551 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 67/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.1176 - acc: 0.9583 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 68/115\n",
      "7242/7242 [==============================] - 0s 45us/step - loss: 0.1162 - acc: 0.9602 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 69/115\n",
      "7242/7242 [==============================] - 0s 41us/step - loss: 0.1142 - acc: 0.9608 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 70/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.1123 - acc: 0.9630 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 71/115\n",
      "7242/7242 [==============================] - 0s 46us/step - loss: 0.1021 - acc: 0.9660 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 72/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.1053 - acc: 0.9658 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 73/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.1062 - acc: 0.9626 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 74/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.1003 - acc: 0.9660 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 75/115\n",
      "7242/7242 [==============================] - 0s 47us/step - loss: 0.0928 - acc: 0.9717 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 76/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0936 - acc: 0.9709 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 77/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.1011 - acc: 0.9681 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 78/115\n",
      "7242/7242 [==============================] - 0s 46us/step - loss: 0.0856 - acc: 0.9718 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 79/115\n",
      "7242/7242 [==============================] - 0s 47us/step - loss: 0.0853 - acc: 0.9722 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 80/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0807 - acc: 0.9735 - val_loss: 3.9605 - val_acc: 0.7543\n",
      "Epoch 81/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0826 - acc: 0.9735 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 82/115\n",
      "7242/7242 [==============================] - 0s 48us/step - loss: 0.0800 - acc: 0.9753 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 83/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0819 - acc: 0.9747 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 84/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0808 - acc: 0.9740 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 85/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.0754 - acc: 0.9780 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 86/115\n",
      "7242/7242 [==============================] - 0s 47us/step - loss: 0.0694 - acc: 0.9808 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 87/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0647 - acc: 0.9840 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 88/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0743 - acc: 0.9787 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 89/115\n",
      "7242/7242 [==============================] - 0s 57us/step - loss: 0.0836 - acc: 0.9735 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 90/115\n",
      "7242/7242 [==============================] - 0s 66us/step - loss: 0.0838 - acc: 0.9718 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 91/115\n",
      "7242/7242 [==============================] - 0s 48us/step - loss: 0.0735 - acc: 0.9783 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 92/115\n",
      "7242/7242 [==============================] - 0s 49us/step - loss: 0.0581 - acc: 0.9838 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 93/115\n",
      "7242/7242 [==============================] - 0s 47us/step - loss: 0.0593 - acc: 0.9830 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 94/115\n",
      "7242/7242 [==============================] - 0s 46us/step - loss: 0.0541 - acc: 0.9859 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 95/115\n",
      "7242/7242 [==============================] - 0s 45us/step - loss: 0.0522 - acc: 0.9878 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 96/115\n",
      "7242/7242 [==============================] - 0s 45us/step - loss: 0.0511 - acc: 0.9865 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 97/115\n",
      "7242/7242 [==============================] - 0s 52us/step - loss: 0.0551 - acc: 0.9848 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 98/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.0494 - acc: 0.9887 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 99/115\n",
      "7242/7242 [==============================] - 0s 61us/step - loss: 0.0514 - acc: 0.9866 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 100/115\n",
      "7242/7242 [==============================] - 0s 50us/step - loss: 0.0624 - acc: 0.9818 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 101/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0793 - acc: 0.9736 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 102/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.0587 - acc: 0.9825 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 103/115\n",
      "7242/7242 [==============================] - 0s 42us/step - loss: 0.0707 - acc: 0.9811 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 104/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0455 - acc: 0.9880 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 105/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0468 - acc: 0.9885 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 106/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0397 - acc: 0.9919 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 107/115\n",
      "7242/7242 [==============================] - 0s 43us/step - loss: 0.0338 - acc: 0.9939 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 108/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0348 - acc: 0.9931 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 109/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0345 - acc: 0.9928 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 110/115\n",
      "7242/7242 [==============================] - 0s 39us/step - loss: 0.0338 - acc: 0.9921 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 111/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.0507 - acc: 0.9855 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 112/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0864 - acc: 0.9703 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 113/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0451 - acc: 0.9887 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 114/115\n",
      "7242/7242 [==============================] - 0s 40us/step - loss: 0.0320 - acc: 0.9930 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 115/115\n",
      "7242/7242 [==============================] - 0s 44us/step - loss: 0.0394 - acc: 0.9917 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "3622/3622 [==============================] - 0s 11us/step\n",
      "7242/7242 [==============================] - 0s 11us/step\n",
      "Train on 7243 samples, validate on 3622 samples\n",
      "Epoch 1/115\n",
      "7243/7243 [==============================] - 1s 85us/step - loss: 0.4908 - acc: 0.7892 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 2/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.4628 - acc: 0.7975 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 3/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.4543 - acc: 0.8022 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 4/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.4475 - acc: 0.8045 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 5/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.4412 - acc: 0.8093 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 6/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.4363 - acc: 0.8104 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 7/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.4303 - acc: 0.8140 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 8/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.4265 - acc: 0.8143 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 9/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.4216 - acc: 0.8155 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 10/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.4148 - acc: 0.8186 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 11/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.4099 - acc: 0.8229 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 12/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.4020 - acc: 0.8253 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 13/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.3955 - acc: 0.8280 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 14/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.3901 - acc: 0.8335 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 15/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.3868 - acc: 0.8318 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 16/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.3782 - acc: 0.8392 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 17/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.3711 - acc: 0.8408 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 18/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.3658 - acc: 0.8451 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 19/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.3586 - acc: 0.8488 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 20/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.3566 - acc: 0.8485 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 21/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.3482 - acc: 0.8508 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 22/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.3431 - acc: 0.8528 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 23/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.3332 - acc: 0.8578 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 24/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.3299 - acc: 0.8626 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 25/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.3223 - acc: 0.8640 - val_loss: 3.9605 - val_acc: 0.7543\n",
      "Epoch 26/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.3153 - acc: 0.8643 - val_loss: 12.2784 - val_acc: 0.2380\n",
      "Epoch 27/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.3119 - acc: 0.8728 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 28/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.3038 - acc: 0.8753 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 29/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.2986 - acc: 0.8757 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 30/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.2947 - acc: 0.8762 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 31/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.2865 - acc: 0.8788 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 32/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.2853 - acc: 0.8843 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 33/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.2761 - acc: 0.8866 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 34/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.2706 - acc: 0.8911 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 35/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.2671 - acc: 0.8897 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 36/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.2617 - acc: 0.8936 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 37/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.2579 - acc: 0.8971 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 38/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.2508 - acc: 0.8951 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 39/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.2442 - acc: 0.8999 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 40/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.2403 - acc: 0.9028 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 41/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.2339 - acc: 0.9076 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 42/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.2323 - acc: 0.9083 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 43/115\n",
      "7243/7243 [==============================] - 0s 58us/step - loss: 0.2254 - acc: 0.9080 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 44/115\n",
      "7243/7243 [==============================] - 0s 66us/step - loss: 0.2217 - acc: 0.9155 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 45/115\n",
      "7243/7243 [==============================] - 0s 60us/step - loss: 0.2121 - acc: 0.9192 - val_loss: 4.5213 - val_acc: 0.7189\n",
      "Epoch 46/115\n",
      "7243/7243 [==============================] - 0s 68us/step - loss: 0.2107 - acc: 0.9198 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 47/115\n",
      "7243/7243 [==============================] - 0s 63us/step - loss: 0.2063 - acc: 0.9192 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 48/115\n",
      "7243/7243 [==============================] - 0s 61us/step - loss: 0.2036 - acc: 0.9225 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 49/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.1975 - acc: 0.9234 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 50/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.1919 - acc: 0.9268 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 51/115\n",
      "7243/7243 [==============================] - 0s 50us/step - loss: 0.1838 - acc: 0.9307 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 52/115\n",
      "7243/7243 [==============================] - 0s 57us/step - loss: 0.1806 - acc: 0.9329 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 53/115\n",
      "7243/7243 [==============================] - 0s 49us/step - loss: 0.1881 - acc: 0.9294 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 54/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.1770 - acc: 0.9346 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 55/115\n",
      "7243/7243 [==============================] - 0s 59us/step - loss: 0.1678 - acc: 0.9372 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 56/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.1649 - acc: 0.9408 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 57/115\n",
      "7243/7243 [==============================] - 0s 48us/step - loss: 0.1583 - acc: 0.9415 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 58/115\n",
      "7243/7243 [==============================] - 0s 57us/step - loss: 0.1559 - acc: 0.9430 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 59/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.1528 - acc: 0.9431 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 60/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.1490 - acc: 0.9439 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 61/115\n",
      "7243/7243 [==============================] - 0s 48us/step - loss: 0.1485 - acc: 0.9451 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 62/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.1436 - acc: 0.9488 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 63/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.1431 - acc: 0.9455 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 64/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.1386 - acc: 0.9508 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 65/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.1302 - acc: 0.9549 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 66/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.1261 - acc: 0.9554 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 67/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.1210 - acc: 0.9616 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 68/115\n",
      "7243/7243 [==============================] - 0s 48us/step - loss: 0.1192 - acc: 0.9619 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 69/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.1180 - acc: 0.9615 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 70/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.1265 - acc: 0.9533 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 71/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.1149 - acc: 0.9595 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 72/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.1147 - acc: 0.9604 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 73/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.1100 - acc: 0.9634 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 74/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.1032 - acc: 0.9667 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 75/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.1041 - acc: 0.9658 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 76/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.0970 - acc: 0.9703 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 77/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.0904 - acc: 0.9692 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 78/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.0974 - acc: 0.9678 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 79/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.1043 - acc: 0.9629 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 80/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.0881 - acc: 0.9725 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 81/115\n",
      "7243/7243 [==============================] - 0s 55us/step - loss: 0.0890 - acc: 0.9714 - val_loss: 3.9694 - val_acc: 0.7537\n",
      "Epoch 82/115\n",
      "7243/7243 [==============================] - 0s 57us/step - loss: 0.0868 - acc: 0.9725 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 83/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.0830 - acc: 0.9746 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 84/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.0785 - acc: 0.9779 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 85/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.0741 - acc: 0.9790 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 86/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.0712 - acc: 0.9778 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 87/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.0751 - acc: 0.9769 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 88/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.0862 - acc: 0.9716 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 89/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.0729 - acc: 0.9778 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 90/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.0675 - acc: 0.9801 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 91/115\n",
      "7243/7243 [==============================] - 0s 41us/step - loss: 0.0603 - acc: 0.9850 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 92/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.0613 - acc: 0.9823 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 93/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.0763 - acc: 0.9743 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 94/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.0693 - acc: 0.9771 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 95/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.0574 - acc: 0.9830 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 96/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.0591 - acc: 0.9844 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 97/115\n",
      "7243/7243 [==============================] - 0s 55us/step - loss: 0.0593 - acc: 0.9823 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 98/115\n",
      "7243/7243 [==============================] - 0s 57us/step - loss: 0.0527 - acc: 0.9874 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 99/115\n",
      "7243/7243 [==============================] - 0s 57us/step - loss: 0.0513 - acc: 0.9872 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 100/115\n",
      "7243/7243 [==============================] - 0s 50us/step - loss: 0.0492 - acc: 0.9885 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 101/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.0485 - acc: 0.9867 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 102/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.0734 - acc: 0.9756 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 103/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.0604 - acc: 0.9790 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 104/115\n",
      "7243/7243 [==============================] - 0s 42us/step - loss: 0.0693 - acc: 0.9774 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 105/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.0505 - acc: 0.9876 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 106/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.0391 - acc: 0.9914 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 107/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.0380 - acc: 0.9921 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 108/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.0435 - acc: 0.9884 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 109/115\n",
      "7243/7243 [==============================] - 0s 40us/step - loss: 0.0363 - acc: 0.9931 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 110/115\n",
      "7243/7243 [==============================] - 0s 50us/step - loss: 0.0349 - acc: 0.9924 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 111/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.0422 - acc: 0.9888 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 112/115\n",
      "7243/7243 [==============================] - 0s 50us/step - loss: 0.0425 - acc: 0.9895 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 113/115\n",
      "7243/7243 [==============================] - 1s 72us/step - loss: 0.0374 - acc: 0.9921 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 114/115\n",
      "7243/7243 [==============================] - 0s 64us/step - loss: 0.0337 - acc: 0.9927 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 115/115\n",
      "7243/7243 [==============================] - 0s 65us/step - loss: 0.0416 - acc: 0.9885 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "3621/3621 [==============================] - 0s 21us/step\n",
      "7243/7243 [==============================] - 0s 24us/step\n",
      "Train on 7243 samples, validate on 3622 samples\n",
      "Epoch 1/115\n",
      "7243/7243 [==============================] - 1s 115us/step - loss: 0.4808 - acc: 0.7930 - val_loss: 3.9650 - val_acc: 0.7540\n",
      "Epoch 2/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.4548 - acc: 0.8049 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 3/115\n",
      "7243/7243 [==============================] - 0s 58us/step - loss: 0.4469 - acc: 0.8088 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 4/115\n",
      "7243/7243 [==============================] - 0s 60us/step - loss: 0.4417 - acc: 0.8117 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 5/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.4360 - acc: 0.8136 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 6/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.4282 - acc: 0.8144 - val_loss: 3.9605 - val_acc: 0.7543\n",
      "Epoch 7/115\n",
      "7243/7243 [==============================] - 0s 61us/step - loss: 0.4256 - acc: 0.8187 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 8/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.4185 - acc: 0.8189 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 9/115\n",
      "7243/7243 [==============================] - 0s 55us/step - loss: 0.4108 - acc: 0.8277 - val_loss: 3.9689 - val_acc: 0.7537\n",
      "Epoch 10/115\n",
      "7243/7243 [==============================] - 1s 101us/step - loss: 0.4059 - acc: 0.8245 - val_loss: 3.9650 - val_acc: 0.7540\n",
      "Epoch 11/115\n",
      "7243/7243 [==============================] - 1s 86us/step - loss: 0.3998 - acc: 0.8281 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 12/115\n",
      "7243/7243 [==============================] - 0s 68us/step - loss: 0.3952 - acc: 0.8310 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 13/115\n",
      "7243/7243 [==============================] - 0s 63us/step - loss: 0.3914 - acc: 0.8291 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 14/115\n",
      "7243/7243 [==============================] - 0s 63us/step - loss: 0.3836 - acc: 0.8346 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 15/115\n",
      "7243/7243 [==============================] - 0s 49us/step - loss: 0.3761 - acc: 0.8385 - val_loss: 3.9553 - val_acc: 0.7546\n",
      "Epoch 16/115\n",
      "7243/7243 [==============================] - 0s 48us/step - loss: 0.3721 - acc: 0.8411 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 17/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.3640 - acc: 0.8459 - val_loss: 3.9650 - val_acc: 0.7540\n",
      "Epoch 18/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.3612 - acc: 0.8438 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 19/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.3552 - acc: 0.8448 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 20/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.3494 - acc: 0.8509 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 21/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.3430 - acc: 0.8546 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 22/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.3386 - acc: 0.8578 - val_loss: 3.9429 - val_acc: 0.7554\n",
      "Epoch 23/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.3324 - acc: 0.8595 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 24/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.3287 - acc: 0.8619 - val_loss: 3.9605 - val_acc: 0.7543\n",
      "Epoch 25/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.3210 - acc: 0.8637 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 26/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.3167 - acc: 0.8633 - val_loss: 3.9605 - val_acc: 0.7543\n",
      "Epoch 27/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.3114 - acc: 0.8681 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 28/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.3029 - acc: 0.8746 - val_loss: 3.9436 - val_acc: 0.7551\n",
      "Epoch 29/115\n",
      "7243/7243 [==============================] - 0s 44us/step - loss: 0.2992 - acc: 0.8752 - val_loss: 3.9658 - val_acc: 0.7537\n",
      "Epoch 30/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.2922 - acc: 0.8811 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 31/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.2908 - acc: 0.8792 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 32/115\n",
      "7243/7243 [==============================] - 0s 66us/step - loss: 0.2844 - acc: 0.8835 - val_loss: 5.0339 - val_acc: 0.6866\n",
      "Epoch 33/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.2766 - acc: 0.8869 - val_loss: 5.1219 - val_acc: 0.6808\n",
      "Epoch 34/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.2723 - acc: 0.8866 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 35/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.2688 - acc: 0.8864 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 36/115\n",
      "7243/7243 [==============================] - 0s 68us/step - loss: 0.2637 - acc: 0.8895 - val_loss: 3.9516 - val_acc: 0.7548\n",
      "Epoch 37/115\n",
      "7243/7243 [==============================] - 0s 67us/step - loss: 0.2601 - acc: 0.8924 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 38/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.2577 - acc: 0.8948 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 39/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.2493 - acc: 0.8996 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 40/115\n",
      "7243/7243 [==============================] - 0s 57us/step - loss: 0.2423 - acc: 0.9014 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 41/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.2366 - acc: 0.9024 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 42/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.2358 - acc: 0.9046 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 43/115\n",
      "7243/7243 [==============================] - 0s 45us/step - loss: 0.2301 - acc: 0.9083 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 44/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.2242 - acc: 0.9112 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 45/115\n",
      "7243/7243 [==============================] - 0s 48us/step - loss: 0.2211 - acc: 0.9118 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 46/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.2135 - acc: 0.9136 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 47/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.2120 - acc: 0.9161 - val_loss: 5.6208 - val_acc: 0.6505\n",
      "Epoch 48/115\n",
      "7243/7243 [==============================] - 0s 48us/step - loss: 0.2027 - acc: 0.9203 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 49/115\n",
      "7243/7243 [==============================] - 0s 43us/step - loss: 0.2012 - acc: 0.9252 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 50/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.1987 - acc: 0.9221 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 51/115\n",
      "7243/7243 [==============================] - 0s 64us/step - loss: 0.1978 - acc: 0.9219 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 52/115\n",
      "7243/7243 [==============================] - 0s 60us/step - loss: 0.1923 - acc: 0.9260 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 53/115\n",
      "7243/7243 [==============================] - 0s 49us/step - loss: 0.1846 - acc: 0.9275 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 54/115\n",
      "7243/7243 [==============================] - 0s 62us/step - loss: 0.1805 - acc: 0.9325 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 55/115\n",
      "7243/7243 [==============================] - 0s 59us/step - loss: 0.1778 - acc: 0.9304 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 56/115\n",
      "7243/7243 [==============================] - 0s 56us/step - loss: 0.1714 - acc: 0.9347 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 57/115\n",
      "7243/7243 [==============================] - 0s 60us/step - loss: 0.1694 - acc: 0.9344 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 58/115\n",
      "7243/7243 [==============================] - 0s 55us/step - loss: 0.1787 - acc: 0.9335 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 59/115\n",
      "7243/7243 [==============================] - 0s 59us/step - loss: 0.1650 - acc: 0.9373 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 60/115\n",
      "7243/7243 [==============================] - 0s 56us/step - loss: 0.1570 - acc: 0.9406 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 61/115\n",
      "7243/7243 [==============================] - 0s 46us/step - loss: 0.1596 - acc: 0.9395 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 62/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.1480 - acc: 0.9481 - val_loss: 3.9694 - val_acc: 0.7537\n",
      "Epoch 63/115\n",
      "7243/7243 [==============================] - 0s 58us/step - loss: 0.1454 - acc: 0.9456 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 64/115\n",
      "7243/7243 [==============================] - 0s 59us/step - loss: 0.1479 - acc: 0.9438 - val_loss: 3.9472 - val_acc: 0.7551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/115\n",
      "7243/7243 [==============================] - 1s 74us/step - loss: 0.1449 - acc: 0.9485 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 66/115\n",
      "7243/7243 [==============================] - 1s 85us/step - loss: 0.1362 - acc: 0.9508 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 67/115\n",
      "7243/7243 [==============================] - 1s 94us/step - loss: 0.1387 - acc: 0.9497 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 68/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.1337 - acc: 0.9528 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 69/115\n",
      "7243/7243 [==============================] - 0s 68us/step - loss: 0.1278 - acc: 0.9554 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 70/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.1257 - acc: 0.9550 - val_loss: 12.2243 - val_acc: 0.2416\n",
      "Epoch 71/115\n",
      "7243/7243 [==============================] - 0s 47us/step - loss: 0.1269 - acc: 0.9542 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 72/115\n",
      "7243/7243 [==============================] - 0s 64us/step - loss: 0.1192 - acc: 0.9569 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 73/115\n",
      "7243/7243 [==============================] - 1s 70us/step - loss: 0.1245 - acc: 0.9540 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 74/115\n",
      "7243/7243 [==============================] - 0s 67us/step - loss: 0.1209 - acc: 0.9562 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 75/115\n",
      "7243/7243 [==============================] - 0s 56us/step - loss: 0.1125 - acc: 0.9590 - val_loss: 3.9460 - val_acc: 0.7551\n",
      "Epoch 76/115\n",
      "7243/7243 [==============================] - 0s 61us/step - loss: 0.1125 - acc: 0.9594 - val_loss: 3.9516 - val_acc: 0.7548\n",
      "Epoch 77/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.1052 - acc: 0.9642 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 78/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.1040 - acc: 0.9648 - val_loss: 3.9516 - val_acc: 0.7548\n",
      "Epoch 79/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.1007 - acc: 0.9651 - val_loss: 3.9516 - val_acc: 0.7548\n",
      "Epoch 80/115\n",
      "7243/7243 [==============================] - 0s 58us/step - loss: 0.0981 - acc: 0.9676 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 81/115\n",
      "7243/7243 [==============================] - 0s 50us/step - loss: 0.1002 - acc: 0.9651 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 82/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.1032 - acc: 0.9647 - val_loss: 7.2825 - val_acc: 0.5472\n",
      "Epoch 83/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.0916 - acc: 0.9688 - val_loss: 3.9561 - val_acc: 0.7546\n",
      "Epoch 84/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.0856 - acc: 0.9727 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 85/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.0862 - acc: 0.9717 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 86/115\n",
      "7243/7243 [==============================] - 0s 53us/step - loss: 0.0839 - acc: 0.9731 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 87/115\n",
      "7243/7243 [==============================] - 0s 54us/step - loss: 0.0815 - acc: 0.9731 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 88/115\n",
      "7243/7243 [==============================] - 0s 51us/step - loss: 0.0804 - acc: 0.9757 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 89/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.0809 - acc: 0.9745 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 90/115\n",
      "7243/7243 [==============================] - 0s 56us/step - loss: 0.0926 - acc: 0.9692 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 91/115\n",
      "7243/7243 [==============================] - 0s 62us/step - loss: 0.0846 - acc: 0.9705 - val_loss: 4.0006 - val_acc: 0.7518\n",
      "Epoch 92/115\n",
      "7243/7243 [==============================] - 0s 59us/step - loss: 0.0877 - acc: 0.9721 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 93/115\n",
      "7243/7243 [==============================] - 0s 60us/step - loss: 0.0687 - acc: 0.9792 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 94/115\n",
      "7243/7243 [==============================] - 0s 65us/step - loss: 0.0715 - acc: 0.9774 - val_loss: 3.9427 - val_acc: 0.7554\n",
      "Epoch 95/115\n",
      "7243/7243 [==============================] - 0s 65us/step - loss: 0.0700 - acc: 0.9787 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 96/115\n",
      "7243/7243 [==============================] - 0s 64us/step - loss: 0.0924 - acc: 0.9681 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 97/115\n",
      "7243/7243 [==============================] - 0s 64us/step - loss: 0.0713 - acc: 0.9782 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 98/115\n",
      "7243/7243 [==============================] - 0s 66us/step - loss: 0.0579 - acc: 0.9847 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 99/115\n",
      "7243/7243 [==============================] - 0s 67us/step - loss: 0.0565 - acc: 0.9837 - val_loss: 12.3088 - val_acc: 0.2363\n",
      "Epoch 100/115\n",
      "7243/7243 [==============================] - 0s 65us/step - loss: 0.0603 - acc: 0.9823 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 101/115\n",
      "7243/7243 [==============================] - 0s 69us/step - loss: 0.0619 - acc: 0.9801 - val_loss: 4.9972 - val_acc: 0.6900\n",
      "Epoch 102/115\n",
      "7243/7243 [==============================] - 0s 62us/step - loss: 0.0571 - acc: 0.9844 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 103/115\n",
      "7243/7243 [==============================] - 1s 70us/step - loss: 0.0597 - acc: 0.9821 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 104/115\n",
      "7243/7243 [==============================] - 1s 69us/step - loss: 0.0585 - acc: 0.9848 - val_loss: 3.9516 - val_acc: 0.7548\n",
      "Epoch 105/115\n",
      "7243/7243 [==============================] - 0s 63us/step - loss: 0.0577 - acc: 0.9837 - val_loss: 3.9663 - val_acc: 0.7537\n",
      "Epoch 106/115\n",
      "7243/7243 [==============================] - 0s 67us/step - loss: 0.0544 - acc: 0.9845 - val_loss: 4.2438 - val_acc: 0.7366\n",
      "Epoch 107/115\n",
      "7243/7243 [==============================] - 1s 73us/step - loss: 0.0576 - acc: 0.9841 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 108/115\n",
      "7243/7243 [==============================] - 0s 64us/step - loss: 0.0551 - acc: 0.9847 - val_loss: 3.9605 - val_acc: 0.7543\n",
      "Epoch 109/115\n",
      "7243/7243 [==============================] - 0s 61us/step - loss: 0.0526 - acc: 0.9862 - val_loss: 12.3044 - val_acc: 0.2366\n",
      "Epoch 110/115\n",
      "7243/7243 [==============================] - 0s 58us/step - loss: 0.0690 - acc: 0.9761 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 111/115\n",
      "7243/7243 [==============================] - 0s 52us/step - loss: 0.0548 - acc: 0.9859 - val_loss: 5.4896 - val_acc: 0.6590\n",
      "Epoch 112/115\n",
      "7243/7243 [==============================] - 0s 63us/step - loss: 0.0767 - acc: 0.9758 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 113/115\n",
      "7243/7243 [==============================] - 0s 49us/step - loss: 0.0520 - acc: 0.9843 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 114/115\n",
      "7243/7243 [==============================] - 0s 60us/step - loss: 0.0396 - acc: 0.9923 - val_loss: 3.9650 - val_acc: 0.7540\n",
      "Epoch 115/115\n",
      "7243/7243 [==============================] - 0s 55us/step - loss: 0.0361 - acc: 0.9934 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "3621/3621 [==============================] - 0s 13us/step\n",
      "7243/7243 [==============================] - 0s 13us/step\n",
      "Train on 10864 samples, validate on 3622 samples\n",
      "Epoch 1/115\n",
      "10864/10864 [==============================] - 1s 92us/step - loss: 0.4798 - acc: 0.7911 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 2/115\n",
      "10864/10864 [==============================] - 1s 53us/step - loss: 0.4579 - acc: 0.8036 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 3/115\n",
      "10864/10864 [==============================] - 1s 51us/step - loss: 0.4476 - acc: 0.8092 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 4/115\n",
      "10864/10864 [==============================] - 1s 54us/step - loss: 0.4418 - acc: 0.8112 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 5/115\n",
      "10864/10864 [==============================] - 1s 53us/step - loss: 0.4350 - acc: 0.8114 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 6/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.4301 - acc: 0.8155 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 7/115\n",
      "10864/10864 [==============================] - 1s 54us/step - loss: 0.4232 - acc: 0.8184 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 8/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.4193 - acc: 0.8213 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 9/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.4134 - acc: 0.8230 - val_loss: 12.2089 - val_acc: 0.2424\n",
      "Epoch 10/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.4086 - acc: 0.8248 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 11/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.4020 - acc: 0.8308 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 12/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.3980 - acc: 0.8297 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 13/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.3924 - acc: 0.8338 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 14/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.3883 - acc: 0.8340 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 15/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.3824 - acc: 0.8380 - val_loss: 3.9605 - val_acc: 0.7543\n",
      "Epoch 16/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.3777 - acc: 0.8382 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 17/115\n",
      "10864/10864 [==============================] - 1s 51us/step - loss: 0.3723 - acc: 0.8410 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 18/115\n",
      "10864/10864 [==============================] - 1s 54us/step - loss: 0.3659 - acc: 0.8446 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 19/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.3622 - acc: 0.8434 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 20/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.3563 - acc: 0.8490 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 21/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.3512 - acc: 0.8515 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 22/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.3449 - acc: 0.8534 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 23/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.3389 - acc: 0.8560 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 24/115\n",
      "10864/10864 [==============================] - 1s 54us/step - loss: 0.3337 - acc: 0.8580 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 25/115\n",
      "10864/10864 [==============================] - 1s 62us/step - loss: 0.3301 - acc: 0.8604 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 26/115\n",
      "10864/10864 [==============================] - 1s 55us/step - loss: 0.3220 - acc: 0.8641 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 27/115\n",
      "10864/10864 [==============================] - 1s 54us/step - loss: 0.3166 - acc: 0.8675 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 28/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.3122 - acc: 0.8676 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 29/115\n",
      "10864/10864 [==============================] - 1s 58us/step - loss: 0.3076 - acc: 0.8713 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 30/115\n",
      "10864/10864 [==============================] - 1s 53us/step - loss: 0.3001 - acc: 0.8730 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 31/115\n",
      "10864/10864 [==============================] - 1s 55us/step - loss: 0.2931 - acc: 0.8789 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 32/115\n",
      "10864/10864 [==============================] - 1s 55us/step - loss: 0.2913 - acc: 0.8791 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 33/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.2866 - acc: 0.8831 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 34/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.2842 - acc: 0.8830 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 35/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.2757 - acc: 0.8860 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 36/115\n",
      "10864/10864 [==============================] - 1s 53us/step - loss: 0.2697 - acc: 0.8911 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 37/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.2640 - acc: 0.8918 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 38/115\n",
      "10864/10864 [==============================] - 1s 51us/step - loss: 0.2576 - acc: 0.8965 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 39/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.2553 - acc: 0.9008 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 40/115\n",
      "10864/10864 [==============================] - 1s 52us/step - loss: 0.2495 - acc: 0.8976 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 41/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.2452 - acc: 0.9026 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 42/115\n",
      "10864/10864 [==============================] - 1s 80us/step - loss: 0.2400 - acc: 0.9031 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 43/115\n",
      "10864/10864 [==============================] - 1s 61us/step - loss: 0.2371 - acc: 0.9042 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 44/115\n",
      "10864/10864 [==============================] - 1s 85us/step - loss: 0.2303 - acc: 0.9102 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 45/115\n",
      "10864/10864 [==============================] - 1s 72us/step - loss: 0.2325 - acc: 0.9068 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 46/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.2225 - acc: 0.9112 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 47/115\n",
      "10864/10864 [==============================] - 1s 51us/step - loss: 0.2189 - acc: 0.9154 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 48/115\n",
      "10864/10864 [==============================] - 0s 45us/step - loss: 0.2168 - acc: 0.9125 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 49/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.2116 - acc: 0.9170 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 50/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.2039 - acc: 0.9219 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 51/115\n",
      "10864/10864 [==============================] - 1s 52us/step - loss: 0.1978 - acc: 0.9230 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 52/115\n",
      "10864/10864 [==============================] - 1s 51us/step - loss: 0.1986 - acc: 0.9221 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 53/115\n",
      "10864/10864 [==============================] - 1s 71us/step - loss: 0.1921 - acc: 0.9227 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 54/115\n",
      "10864/10864 [==============================] - 1s 54us/step - loss: 0.1888 - acc: 0.9263 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 55/115\n",
      "10864/10864 [==============================] - 0s 45us/step - loss: 0.1835 - acc: 0.9270 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 56/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.1936 - acc: 0.9244 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 57/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.1769 - acc: 0.9322 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 58/115\n",
      "10864/10864 [==============================] - 0s 45us/step - loss: 0.1718 - acc: 0.9373 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 59/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.1710 - acc: 0.9341 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 60/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.1691 - acc: 0.9362 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 61/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.1620 - acc: 0.9396 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 62/115\n",
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.1606 - acc: 0.9394 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 63/115\n",
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.1657 - acc: 0.9353 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 64/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.1623 - acc: 0.9392 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 65/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.1485 - acc: 0.9455 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 66/115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.1447 - acc: 0.9469 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 67/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.1458 - acc: 0.9446 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 68/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.1438 - acc: 0.9450 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 69/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.1370 - acc: 0.9497 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 70/115\n",
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.1353 - acc: 0.9517 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 71/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.1355 - acc: 0.9504 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 72/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.1334 - acc: 0.9484 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 73/115\n",
      "10864/10864 [==============================] - 1s 53us/step - loss: 0.1282 - acc: 0.9525 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 74/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.1257 - acc: 0.9557 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 75/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.1257 - acc: 0.9508 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 76/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.1252 - acc: 0.9560 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 77/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.1199 - acc: 0.9566 - val_loss: 3.9383 - val_acc: 0.7557\n",
      "Epoch 78/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.1168 - acc: 0.9593 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 79/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.1122 - acc: 0.9598 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 80/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.1090 - acc: 0.9623 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 81/115\n",
      "10864/10864 [==============================] - 0s 44us/step - loss: 0.1107 - acc: 0.9612 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 82/115\n",
      "10864/10864 [==============================] - 0s 45us/step - loss: 0.1059 - acc: 0.9627 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 83/115\n",
      "10864/10864 [==============================] - 0s 44us/step - loss: 0.1068 - acc: 0.9611 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 84/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.0998 - acc: 0.9661 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 85/115\n",
      "10864/10864 [==============================] - 0s 44us/step - loss: 0.1123 - acc: 0.9589 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 86/115\n",
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.0982 - acc: 0.9658 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 87/115\n",
      "10864/10864 [==============================] - 0s 45us/step - loss: 0.0908 - acc: 0.9688 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 88/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0998 - acc: 0.9643 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 89/115\n",
      "10864/10864 [==============================] - 0s 45us/step - loss: 0.1124 - acc: 0.9603 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 90/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.0924 - acc: 0.9680 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 91/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0846 - acc: 0.9702 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 92/115\n",
      "10864/10864 [==============================] - 1s 50us/step - loss: 0.0825 - acc: 0.9731 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 93/115\n",
      "10864/10864 [==============================] - 1s 77us/step - loss: 0.0825 - acc: 0.9722 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 94/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0858 - acc: 0.9695 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 95/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.0766 - acc: 0.9762 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 96/115\n",
      "10864/10864 [==============================] - 1s 79us/step - loss: 0.0878 - acc: 0.9689 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 97/115\n",
      "10864/10864 [==============================] - 1s 51us/step - loss: 0.0922 - acc: 0.9676 - val_loss: 3.9472 - val_acc: 0.7551\n",
      "Epoch 98/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.0847 - acc: 0.9703 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 99/115\n",
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.0725 - acc: 0.9756 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 100/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0693 - acc: 0.9771 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 101/115\n",
      "10864/10864 [==============================] - 0s 43us/step - loss: 0.0709 - acc: 0.9765 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 102/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.0840 - acc: 0.9699 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 103/115\n",
      "10864/10864 [==============================] - 0s 44us/step - loss: 0.0836 - acc: 0.9707 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 104/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0716 - acc: 0.9761 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 105/115\n",
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.0635 - acc: 0.9806 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 106/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.0646 - acc: 0.9783 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 107/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0572 - acc: 0.9836 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 108/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.0597 - acc: 0.9798 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 109/115\n",
      "10864/10864 [==============================] - 0s 45us/step - loss: 0.0772 - acc: 0.9738 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 110/115\n",
      "10864/10864 [==============================] - 1s 48us/step - loss: 0.0704 - acc: 0.9751 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 111/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0596 - acc: 0.9800 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 112/115\n",
      "10864/10864 [==============================] - 1s 49us/step - loss: 0.0545 - acc: 0.9832 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 113/115\n",
      "10864/10864 [==============================] - 1s 47us/step - loss: 0.0764 - acc: 0.9748 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 114/115\n",
      "10864/10864 [==============================] - 1s 46us/step - loss: 0.0584 - acc: 0.9809 - val_loss: 12.1709 - val_acc: 0.2449\n",
      "Epoch 115/115\n",
      "10864/10864 [==============================] - 0s 46us/step - loss: 0.0557 - acc: 0.9830 - val_loss: 12.1709 - val_acc: 0.2449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x1229264a8>,\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'dense_layer_sizes': [[80, 160]], 'epochs': [115], 'activation': ['relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_size_candidates = [[80, 160]]\n",
    "classifier = KerasClassifier(make_model)\n",
    "validator = GridSearchCV(classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     'epochs': [115],\n",
    "                                     'activation': ['relu'],\n",
    "                                    }, n_jobs=1)\n",
    "validator.fit(X_train_scaled, y_train_categorical, validation_data=(X_test, y_test_categorical))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters of the best model are: \n",
      "{'activation': 'relu', 'dense_layer_sizes': [80, 160], 'epochs': 115}\n",
      "0.7546944035318665\n"
     ]
    }
   ],
   "source": [
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)\n",
    "print(validator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3622/3622 [==============================] - 0s 24us/step\n",
      "loss :  1.2595250837891587\n",
      "acc :  0.7680839315295417\n"
     ]
    }
   ],
   "source": [
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(X_test_scaled, y_test_categorical)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = os.path.join('..', 'model', 'grammy_prediction_model.h5')\n",
    "best_model.save(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Acousticness', 'Danceability', 'Duration (ms)', 'Energy',\n",
       "       'Instrumentalness', 'Key', 'Liveness', 'Loudness', 'Mode',\n",
       "       'Speechiness', 'Tempo', 'Time Signature', 'Valence', 'Explicit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/grammy_prediction_scaler.sav']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "scaler_file = os.path.join('..', 'model', 'grammy_prediction_scaler.sav')\n",
    "joblib.dump(X_scaler, scaler_file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
